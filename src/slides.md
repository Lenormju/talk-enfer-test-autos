<style>
.reveal h1:first-of-type {
  color: red;
}
</style>

<!-- .slide: data-background-image="./enfer-paradis.jpg" -->

# L'enfer des tests autos

Notes:
* TODO :
  * exemples/anecdotes concrets tout du long
  * exemples de code/archi √† la fin
  * ajouter des images
  * pimper la pr√©sentation avec un peu de CSS (cf le mkslides_config.yml)
  * voir si on garde ou pas le chemin de cr√®te
* TODO feedback meetup Julien :
  * r√©utiliser l'image de la qualit√© selon Rambo
  * mentionner "conduite du changement" lorsqu'on parle de la Culture ?
  * ajouter photo d'Omar Sy "pas de bras, pas de chocolat"
  * la slide sur le feedback fait un peu redite ?
  * ajouter image du bon chasseur
  * mettre l'IDE en light mode, pr√©parer les onglets, ...
  * il y a une slide "fluidit√©" qui a saut√© ou bien ? j'ai loup√© un coche
  * trop d'informations ... (mais comment am√©liorer ?)
  * ajouter une visualisation de la strat√©gie/pyramide de test (couleurs qui couvrent une archi)

---

# Introduction

-v-

## Merci aux sponsors

- TODO sponsors DevFest Toulouse

Notes:
* TODO: logo Kaizen

-v-

## Pr√©sentation

Julien Lenormand üòá

Jonathan Gaffiot üòà
@ Kaizen Solutions

<img src="./logo-kaizen.png" style="position: absolute; right: 500px; top: 500px; width: auto; height: auto" />

Notes:
* on n'est pas parfait, des fois on ne teste pas (assez), ou pas auto
* plut√¥t qu'un disclaimer, penser √† expliciter qu'on a le choix entre :
  √©crire ses tests, ou tester manuellement, et bien souvent en prod

-v-

## Sondage

* Qui trouve que les tests c'est l'enfer ? <!-- .element: class="fragment" -->
* Qui trouve que c'est le paradis ? <!-- .element: class="fragment" -->

---

# Tester c'est le Bien

üòá üòá üòá

-v-

## Oui mais... c'est quoi tester ?

* tester = s'assurer de la r√©ponse attendue de la part du syst√®me dans un certain √©tat √† un stimuli particulier   <!-- .element: class="fragment" -->
  * r√©ponse attendue ?  <!-- .element: class="fragment" -->
  * certain √©tat ?  <!-- .element: class="fragment" -->
  * quel stimuli ?  <!-- .element: class="fragment" -->
  * et les effets de bords de mon syst√®me ?  <!-- .element: class="fragment" -->
* üòà plus de questions qu'avant la d√©finition... <!-- .element: class="fragment" -->

Notes:
* c'est quoi tester ? c'est quoi tester automatiquement ? (moment chiant avec des d√©finitions)
* c'est toujours difficile (et chiant !) les d√©finitions  !
* action, r√©action, stimuli, SUT, oracle
  * d√©finiton test = s'assurer de la r√©ponse attendue de la part du syst√®me dans un certain √©tat √† un stimuli particulier
  * expliciter les pi√®ges :
    + r√©ponse attendue ? oui mais quand effet de bord ? LLM ? r√©sultat de simu ? (besoin d'un oracle)
    + certain √©tat ? c'est quoi les √©tats de mon syst√®me ? comment je mets mon syst√®me dans un √©tat particulier ?
    + quel stimulus ? quelle r√©ponse ? comment j'y acc√®de ?
    + et les effets de bords de mon syst√®me ? ses d√©pdendances √† d'autres syst√®mes ?
* on est pas bien avanc√©...

-v-

## Pourquoi tester ?

Qualit√© avec un grand Q :  <!-- .element: class="fragment" -->
* ISO 9000 : aptitude d'un ensemble de caract√©ristiques intrins√®ques d'un objet (produit, service,...) √† satisfaire des exigences  <!-- .element: class="fragment" -->
* Rambo Python : fiabilit√©, maintenabilit√©, √©volutivit√©, s√©curit√©  <!-- .element: class="fragment" -->

La qualit√© n'est pas automatique, surtout pour du logiciel. <!-- .element: class="fragment" -->

Notes:
* Faire du logiciel ce n'est pas si simple

-v-

## Fiabilit√© du code

* Le logiciel est particulier : complexe, immat√©riel, fluide  <!-- .element: class="fragment" -->
  + complexe  <!-- .element: class="fragment" -->
    - chaque ligne est une action
    - n√©cessairement des effets de bord
    - explosion combinatoire des chemins d'ex√©cution
    - empilement de couches de fonctions, d'objets, de librairies
  + immat√©riel <!-- .element: class="fragment" -->
    - pas d'exp√©rience imm√©diate, visuelle
    - pas d'inspection
    - pas d'exp√©rience dans la vie de tous les jours
  + fluide <!-- .element: class="fragment" -->
    - change facilement
    - partageable, r√©utilisable
    - tempo technologique fr√©n√©tique
* üòà le code c'est trop dur pour vos petites cervelles d'humains !  <!-- .element: class="fragment" -->

Notes:
* et les autres aspects de la qualit√© d'apr√®s Rambo Python ? maintenabilit√©/√©volutivit√©/s√©curit√© !
* s'autoriser le refactoring, conserver du code maintenable
* stabilit√© / perennit√© / scalabilit√© humaine-temporelle-technique-complexit√©-busfactor
  * Tests auto = moyen de scaler dans le temps, la taille, les personnes, les techs, ...
  * pouvoir survivre √† un changement d'√©quipe
* quelle valeur √† un logiciel qui ne peut pas √™tre test√© automatiquement ? uniquement court-terme
* pas d'autom == risque projet
* une certaine forme de sp√©cification (c'est plus simple de savoir ce que le code doit faire, quand c'est litt√©ralement commit√© dans le repo)
    * et encore mieux, elle se v√©rifie toute seule !!
* ex√©cution automatique/syst√©matique -> pas besoin de devoir s'en souvenir (CI, make, ...)
* emp√™che le "Fear driven development"
  * Comment faire du fearless refactoring sans Rust ni test ?
* √©vite le "tomb√© en marche"
* non-reg
* Sens strict de refactoring, pas de refactoring sans garantie que le comportement "observable" (externe) n'a pas √©volu√©
  * n√©cessaire pour dompter la dette technique

-v-

## Confiance et s√©r√©nit√©

* les tests aident √† r√©soudre ces probl√®mes :  <!-- .element: class="fragment" -->
  + üòá v√©rifier que ce que j'ai chang√© fonctionne correctement  <!-- .element: class="fragment" -->
  + üòá v√©rifier que ce que je n'ai pas chang√© continue de fonctionner  <!-- .element: class="fragment" -->
  + üòá v√©rifier que l'ensemble fonctionne <!-- .element: class="fragment" -->
  + üòá mise en prod le vendredi !  <!-- .element: class="fragment" -->

* on peut donc :  <!-- .element: class="fragment" -->
  * refactorer ou faire √©voluer le code en confiance  <!-- .element: class="fragment" -->
  * avoir des preuves qu'il fonctionne correctement (plus de "tomb√© en marche") <!-- .element: class="fragment" -->
  * laisser d'autres personnes le modifier  <!-- .element: class="fragment" -->

Notes:
* s√©r√©nit√©

-v-

## √âthique professionnelle

* le code peut √™tre une passion üòá   <!-- .element: class="fragment" -->
* ... et donc une torture ! üòà   <!-- .element: class="fragment" -->
* livrer du "bon" code :  <!-- .element: class="fragment" -->
  * responsabilit√© perso/pro  <!-- .element: class="fragment" -->
  * "√©lever le niveau" - devise des crafteurs  <!-- .element: class="fragment" -->
  * une question de maturit√© ?  <!-- .element: class="fragment" -->

Notes:
* cf Craft et d√©ontologie
* crit√®re de validit√© de ce qui est livr√© ("si c'est pas test√©, c'est r√©put√© ne pas marcher")
* pas oblig√© de faire comme les autres
* livraison, recette

-v-

## Rentabilit√©

* pas simple √† mesurer (scientifiquement)  <!-- .element: class="fragment" -->
* Accelerate ?  <!-- .element: class="fragment" -->
* argument d'autorit√© : <!-- .element: class="fragment" -->
  * Google, Microsoft, Netflix, Apple le font !!!  <!-- .element: class="fragment" -->
  * et tous les projets libres qu'on utilise tous les jours !!!  <!-- .element: class="fragment" -->
* se concentrer sur des t√¢ches √† forte valeur ajout√©e  <!-- .element: class="fragment" -->

Notes:
* Accelerate
* autres preuves d'efficacit√© ? (cf scientific proofs)
* se concentrer sur des activit√©s √† forte valeur ajout√©e, par rapport √† r√©p√©ter des tests
* Seul moyen de tenir la cadence
* est-ce qu'il est vrai que les bugs co√ªtent + cher √† corriger s'ils sont d√©couverts plus tard ? (preuves !!)

-v-

## Pourquoi c'est important les tests autos en particulier ?

Pour garder la maitrise de son code au fur et √† mesure de son d√©veloppement ! üòá  <!-- .element: class="fragment" -->
 * ex√©cution automatique et syst√©matique -> pas d'oubli ! pas de flemme !  <!-- .element: class="fragment" -->

-v-

## Feedback rapide

* UN BUG üòà !  <!-- .element: class="fragment" -->
  - üòê trouv√© lors de la PR  <!-- .element: class="fragment" -->
  - üò© trouv√© lors des tests en pr√©-prod  <!-- .element: class="fragment" -->
  - üò¢ trouv√© en prod  <!-- .element: class="fragment" -->

* Un feedback rapide üòá <!-- .element: class="fragment" -->
  - facile √† ex√©cuter  <!-- .element: class="fragment" -->
  - r√©sultat rapide <!-- .element: class="fragment" -->
  - facile √† exploiter : log, stracktrace, d√©buggueur... <!-- .element: class="fragment" -->
  - ind√©pendant, pas besoin de "QA"  <!-- .element: class="fragment" -->

Notes:
* ownership de la qualit√© du code, ce n'est pas juste aux QAs, ou utilisateurs de trouver les bugs, "√ßa marche sur ma machine"
* facile √† ex√©cuter : un clic et c'est bon, √ßa part en prod

-v-

## √âvolutivit√© et maintenabilit√©

* les tests sont un ingr√©dient pour la stabilit√© :  <!-- .element: class="fragment" -->
  * dans le temps  <!-- .element: class="fragment" -->
  * √† travers les technologies  <!-- .element: class="fragment" -->
  * malgr√© les √©volutions  <!-- .element: class="fragment" -->
  * pour d√©tecter les r√©gressions  <!-- .element: class="fragment" -->
  * pour survivre √† une absence impr√©vue (bus factor)  <!-- .element: class="fragment" -->
  * pour augmenter efficacement la taille de l'√©quipe  <!-- .element: class="fragment" -->
  * pour augmenter la cadence de livraison  <!-- .element: class="fragment" -->
* pas de test automatis√© = risque projet  <!-- .element: class="fragment" -->

Sondage : <!-- .element: class="fragment" -->

üòà Qui veut mettre en prod 2 ans de code jamais test√© ? <!-- .element: class="fragment" -->

üòàüòàüòà Qui veut faire les tests de 2 ans de code d'un coup ? üòàüòàüòà  <!-- .element: class="fragment" -->

-v-

## Le paradis !

Fin de la conf√©rence ?

Sauf que...  <!-- .element: class="fragment" -->

![](./10845744.jpg)  <!-- .element: class="fragment" -->

Notes:
* une fois qu'on s'est dit √ßa, √ßa para√Æt vachement bien, donc y'a aucune raison de pas en faire
* meme avec l'image recto/verso, ville en feu, b√©b√© zombie
  * "Kid Thrown In The Air Meme: How Dad Sees It Vs How Mom Sees It" cf https://i.imgur.com/qL915f0.jpeg
* Stop au masochisme !
* transition vers la partie suivante

---

# Pourquoi c'est difficile les tests autos ?

Faut bien l'avouer !

Notes:
* TODO: ajouter des exemples concrets √† chacun
* TODO @jonathan mettre des bouts de paradis

-v-

## Pas le temps

* Pas pr√©vu dans le planning/sprint  <!-- .element: class="fragment" -->
* Mon chef/Product Truc me dit de faire des features  <!-- .element: class="fragment" -->
* Deadline en vue  <!-- .element: class="fragment" -->
* Jamais budget√©, jamais valoris√©  <!-- .element: class="fragment" -->
* Projet g√©r√© par le marketing sans aucune exp√©rience de la technique  <!-- .element: class="fragment" -->
* De toute fa√ßon y'aura bien une validation du produit final...  <!-- .element: class="fragment" -->

Notes:
* convaincre (le management et/ou les devs) que c'est utile, avant de se manger une mise-en-prod foir√©e
* d√©pense versus √©conomie
* R√©sultats intangibles

-v-

## Pas appris

* Rarement au programme des formations de dev <!-- .element: class="fragment" -->
  * Ou alors th√©orique et tr√®s court... üòà <!-- .element: class="fragment" -->
  * Mais √ßa s'am√©liore üòá <!-- .element: class="fragment" -->
* Peu pr√©sent dans la litt√©rature (livres, blogs...), les confs, les formations <!-- .element: class="fragment" -->
  * Alors que c'est souvent ~50% des LoC üòà <!-- .element: class="fragment" -->
  * Mais on en parle aujourd'hui ! üòá <!-- .element: class="fragment" -->

Notes:
* JULIEN: anecdote Ensimag, importance pro
* JULIEN: biblio, conf√©rences

<!--
* sauf pour les testeurs de m√©tier, les moldus s'en passeront bien ?
* et encore les testeurs apprennent pas les TU
* pas de formation dans la plupart des cursus master, ou bien th√©orique ou tr√®s court
* assez peu pr√©sent dans la litt√©rature g√©n√©raliste, malgr√© sa pr√©valence et importance (cf biblio)
* pas un sujet "sexy" (formation continue, conf√©rences, ...)
* exemple Ensimag, mon cursus versus ce qui est propos√© actuellement
    * Mon √®cole d'ing√©, ni mon DUT ne m'ont enseign√© le test
    * Le test √®tait une option, une ann√©e, d'une fili√®re
    * les cours de Groz sur la v√©rif statique et la mod√©lisation boite noire
    * Ensimag, examens de SAP en 2014 et 2015 :
      * d√©terminer les (in)variants de boucle
      * preuve d'arr√™t,
      * interpr√®tation abstraite (r√©duction de machines √† √©tats),
      * acc√®s m√©moire invalide,
      * valeurs par d√©faut en Java,
      * d√©tection de la r√©cursion ou de code mort,
      * propagation d'intervalles pour ex√©cution symbolique
      * preuves de comportement de programme
    * https://ensimag.grenoble-inp.fr/fr/formation/analyse-de-code-pour-la-s-ucirc-ret-eacute-et-la-s-eacute-curit-eacute-4mmacss
      * Ce cours est une introduction aux fondements de la s√©mantique et l‚Äôanalyse de programmes. Il offre les bases sur lesquelles s‚Äôappuyer pour sp√©cifier et d√©velopper des applications s√ªres, construire et se servir d‚Äôoutils d‚Äôanalyse et de v√©rification.
      * S√©mantique op√©rationnelle des langages de programmation.
      * Calcul de plus faible pr√©condition et preuve de programmes.
      * Analyse de flot de donn√©es.
      * Analyse statique et interpr√©tation abstraite.
      * Applications √† la compilation, √† la s√ªret√© et √† la s√©curit√© des logiciels.
      * Travaux pratiques √† l'aide de 2 outils industriels.
        * (Frama-C et Coq s√ªrement ?)
    * https://ensimag.grenoble-inp.fr/fr/formation/test-des-syst-egrave-mes-logiciels-5mmtsl6
      * une option parmi 3, pour ceux qui font pas d'Erasmus
      * Pr√©sentation des m√©thodes de test pour assurer la s√ªret√© de fonctionnement des logiciels.
      * Test
      * V√©rification et validation
      * Les tests au cours du cycle de vie.
      * Test structurel des logiciels.
      * Test √† partir des sp√©cifications: partitionnement, combinatoire.
      * M√©thodes de test bas√©es sur des mod√®les, en particulier automates.
      * Analyse des notions de couverture, test mutationnel.
      * Eclairage sur des domaines de test importants:
        * test de performance et test de charge
        * test d'interface
        * test de s√©curit√©.
      * Cours de g√©nie logiciel abordant notamment les cycles de d√©veloppement : cela permet de situer correctement le test dans une activit√© de d√©veloppement.
      * Bonnes connaissances en algorithmique et programmation : √™tre capable d'analyser un programme, de l'ex√©cuter symboliquement "√† la main", fait partie des activit√©s du testeur et est une comp√©tence indispensable pour comprendre les techniques fond√©es sur l'analyse du code.
      * Langages et automates : une partie du cours porte sur de mod√®les et en particulier des machines d'√©tats finis exploit√©es pour engendrer des tests de conformit√©.
      * Bibliographie :
        * Aditya P. Mathur:Foundations of Spftware Testing, Pearson 2008.
        * J-F. Pradat-Peyre, J. Printz: Pratique des tests logiciels, Dunod 2009.
        * Myers, G.J. : The Art of Software Testing. Wiley 1979; r√©√©dit√© 2004.
    * le cours de derni√®re ann√©e
      * zip de quentin pign√©
* "missing semester" ?
* Apprentissage th√©orique (en √©tudes ing√©) versus apprentissage empirique de l'informatique (sur le terrain), en particulier du test
* cf analyse de la ibliographie
-->

-v-

## Mais de quoi on parle ?

* Personne n'est d'accord sur rien ! üòà
  * C'est quoi un test unitaire ? Combien j'en fait ? <!-- .element: class="fragment" -->
  * C'est quoi les autres cat√©gories ? Int√©gration, validation, recette ? C'est quoi la diff√©rence ? <!-- .element: class="fragment" -->
  * Plus de pyramides de tests qu'en Egypte ! <!-- .element: class="fragment" -->
  * Quel m√©tier ? QA, testeur, dev, IVVQ, quality manager ? <!-- .element: class="fragment" -->
* Faut en parler ensemble pour se mettre d'accord ! üòá  <!-- .element: class="fragment" -->

Notes:
* TODO: ajouter des images de pyramides !
* personne n'est d'accord sur rien : 47 pyramides diff√©rentes, le vocabulaire du test,~~les perspectives tech~~, les r√¥les, les niveaux de test
* lister et illustrer avec diff√©rents types de pyramides
    * blague illuminatis (pyramide)
    * On est des √®gyptiens, on a plein plein de pyramides diff√®rentes
* Pyramide originale par Mike Cohn dans "Succeeding with Agile" publi√© en 2009
* Floril√®ge des autres formes : ice cream, hourglass, diamond, upside-down pyramid, trophy (kent beck) ... --> aucune solution universelle
    * https://claude.ai/chat/3ff66008-4cc7-431e-9657-9f4987e7d86c
* Dimensions de la pyramide : vitesse d'ex√©cution, co√ªt √† √©crire/maintenir, quantit√© de code exerc√©e, fid√©lit√© utilisateur, ...
  * Multiples interpr√©tations des dimensions de la pyramide : quantit√©, vitesse d'ex√©cution, confiance, sp√©cificit√©, couverture apport√©e, co√ªt de production, fr√©quence de changement / bug, ...
* Le test c'est un sujet transverse our chaque dev, qu'importe le langage, la stack, le m√©tier, ... Donc tout le monde parle de quelque chose avec un point de vue et un focus diff√®rent, pas toujours mentionn√©
* pr√™t-√†-penser
    * dans quels contextes-projets travaillent les diff√©rentes personnes qui ont propos√© ces pyramides ? et en quelle ann√©e ?
    * ne suffit pas pour appr√©hender le test
    * Testing tools have evolved in 30 years
* jeu des 7314 diff√©rences : industrie, technos, maturit√© du produit, dur√©e de maintenance, culture d'√©quipe, comp√©tences lacunaires, vitesse, confiance, ...
    * il n'y en a pas qu'une seule, mais une par projet ! chaque projet est diff√©rent !
    * chaque projet est (quasi) unique
* anecdote sur le vocabulaire pas unifi√© : du temps de mon stage en autom de test, j'avais travaill√© entre autres sur un glossaire unifi√© entre ISTQB et CFTL
* meilleure d√©finition des axes : "finalit√©, granularit√©, modalit√© d'assertion" (50 shades ...)
* essayons de poser une d√©finition, dans notre contexte, des mots que nous employons
    * diff√©rences entre ISTQB et CFTL, cf mon stage Sogeti
* tous les diff√©rents types de test : carac, fonc, integ, unit, acceptance, user-testing, accessibility, composant-unitaire versus composant-UI, e2e-stack ou e2e-sc√©nario...
    * faire une liste exhaustive des noms ?
    * charge : soak, breakpoint, ... (cf doc de k6 avec de jolis graphiques)
        * K6 typologie : breakpoint, soak, stress, load, ...
    * cf ISO 15010
    * peu de personnes, m√™me dans des livres (exemple Clean Code de Robert C Martin "Uncle Bob"), ne font l'effort de d√©finir
    * Pyramyde invers√© de la valeur : le haut niveau est le plus pertinent, mais cher et fragile ?
        * Facilitation des tests web d'ui (selenium, cypress, playwright)
* QA analyst/tester vs quality engineer vs testeur-automaticien vs "dev" vs IVVQ vs QA "quality advisor" vs test manager ...
* Test error vs test failure : le test n'a pas abouti pour une raison technique (probl√®me de test), le test a abouti mais n'a pas produit le r√©sultat attendu (probl√®me fonctionnel on esp√®re !)
  * distinction "test qui plante" versus "test qui √©choue"
* Imbrication et interconnexion des syst√®mes : les tests au m√™me endroit n'ont pas le m√™me nom / fonction.
* politique vs strat√©gie vs plan de test
* E2e : vertical de la stack ? Ou horizontal du parcours utilisateur ?
* Sanity vs smoke ?
* test fonctionnel + non-fonctionnel : si la perf fait partie des requirements, alors fonctionnel ou pas ?
* [le glossaire ISTQB](https://glossary.istqb.org/en_US/search?term=) donne 601 r√©sultats en anglais, 559 en fran√ßais
* personne n'est d'accord sur les tests, car personne n'utilise les m√™mes d√©finition
  * d√©monstration : pain au chocolat

-v-

## Trop de tests, pas assez ?

* Quelques tests "end-to-end (enfin... plus ou moins... sauf pour la GUI...)  üòà <!-- .element: class="fragment" -->
  * Mais ils prennent des plombes ! <!-- .element: class="fragment" -->
  * Et ils cassent tout le temps ! <!-- .element: class="fragment" -->
  * Et je peux pas les automatiser, il faut que je rentre mes identifiants ! <!-- .element: class="fragment" -->
    * (bon on va cr√©er un user de test... harcoder son mdp quelque part... chut ! üòà) <!-- .element: class="fragment" -->

* 10 ans de tests accumul√©s üòà <!-- .element: class="fragment" -->
  * Chaque fonction est test√©e 10 fois ! <!-- .element: class="fragment" -->
  * Plus de 1000 exigences dans le plan de test ! <!-- .element: class="fragment" -->
  * √áa prend des plombes ! <!-- .element: class="fragment" -->
  * Y'en a toujours 4 ou 5 qui plantent, √©videmment qu'on regarde plus si c'est rouge ! <!-- .element: class="fragment" -->
  * Chaque fois que je touche une ligne j'ai 10 tests √† modifier ! <!-- .element: class="fragment" -->

* Et pourtant on d√©couvre toujours des bugs ! üòà <!-- .element: class="fragment" -->

Notes:
* explosion combinatoire
* cible mouvante et floue
* L'explosion combinatoire rend l'exhaustivit√© impossible
* couplage versus maintenabilit√© en carton, tests cass√©s pas r√©par√©s ("vitre cass√©e"), maintenance des tests v√©cue comme un fardeau
  * le summum : test de mock !
* Tester le mauvais 80% : m√©taphore du streetlight problem ("plus simple de chercher dans la lumi√®re")
* test flaky
  * l'√©quivalent de "pt√®t bin qu'oui, pt√®t bin qu'non"
  * suffit de les relancer plusieurs fois mdr, ~z√©ro confiance
* lenteur, car tests lents et/ou trop de tests
* exemple de Xavier Nopre (cf [post LinkedIn](https://www.linkedin.com/posts/xnopre_pourquoi-jai-mis-plus-de-3-jours-%C3%A0-trouver-activity-7316027544934191104-Otww)), je lui ai dit qu'il y avait un probl√®me, c'est pas cens√© √™tre aussi lent
* exemple de Schneider : board farms
* exemple de Schneider : code dont le run dure des centaines jours !! (√† travers les timezones :p)

-v-

## Punition ou mauvaise volont√© ?

* J'ai pas envie d'√©crire des tests, j'ai test√© √† la mano √ßa marche ! üòà  <!-- .element: class="fragment" -->
* Mes specs sont dans un Word de 200 pages, je peux pas les tester une par une ! üòà <!-- .element: class="fragment" -->
* Pas mon boulot les tests E2E, je fais que mes tests unitaires sur MON code ! üòà <!-- .element: class="fragment" -->
* De toute fa√ßon c'est du C++, c'est trop chiant de g√©rer les effets de bord ! üòà  <!-- .element: class="fragment" -->

Notes:
* des tonnes d'outils diff√©rents, les diff√©rents types de tests √©voqu√©s, les diff√©rents m√©tiers, l'insertion dans le process de production, ...
* s'organiser, planifier et r√©aliser sont des t√¢ches complexes
* l'absence de testeur/expertise/culture dans les projets (des gens form√©s, motiv√©s, avec le mindset ad√©quat)
* > On peut conduire un cheval √† l'abreuvoir, mais pas le forcer √† boire
* certifications ISTQB par le CFTL
* casse-pied de service

-v-

## C'est impossible !

Je peux pas tester...
* j'ai pas le droit de taper sur l'API, elle est payante <!-- .element: class="fragment" -->
* faudrait la DB <!-- .element: class="fragment" -->
* faudrait des identifiants <!-- .element: class="fragment" -->
* c'est de l'embarqu√© sur une carte maison <!-- .element: class="fragment" -->
* c'est un OS propri√©taire obsol√®te depuis longtemps <!-- .element: class="fragment" -->
* une simu prends 3 jours sur le cluster <!-- .element: class="fragment" -->
* c'est pas reproductible <!-- .element: class="fragment" -->

Notes:
* JULIEN: anecdote "juste" ajouter une route sur API
* Ennemis :
  * side-effects ("spooky action at a distance", "que fait cette m√©thode ?"),
  * (global/static) state,
  * IO,
  * singletons,
  * time,
  * locale,
  * network,
  * files,
  * env,
  * GPU,
  * unclear pre/post-conditions,
  * non-determinism,
  * (G)UI vs API,
  * concurrency et threading,
  * random (non-deterministic),
  * complex outputs and high dimensionality
* imitations techniques, mat√©rielles, de co√ªt, ... variabilit√© selon les environnements, pas de donn√©es de test (r√©alistes)
* exemple board farm Schneider
* exemple Windows 10 LTSC 2019 √† Thales
* diff√©rence entre "c'est compliqu√© de r√©aliser le test" (limitations tech) versus "c'est compliqu√© d'√©crire le test" (iceberg, gorille)
* exemple : code des bornes qui √©choue le 29 F√©vrier
* exemple : code du Edge qui est correct sur la timezone 6 mois par an
* anecdote schneider :
  * on me demande de rajouter un param√®tre bool√©en √† une route HTTP, sur un composant sur lequel je n'ai jamais travaill√©
  * je me dis je vais le faire en TDD, commencer par √©crire un test
  * mais y'a aucun test sur le projet, donc je dois commencer par √©crire un test avant
  * j'√©cris un test, je le lance un fois il passe, deux fois il √©choue
  * car il avait une d√©pendance sur une base de donn√©es, laquelle est g√©r√©e par un singleton, qui stocke l'√©tat
  * donc je fixturise le singleton pour le r√©initialiser (ou le d√©truire/reconstruire) afin que mon test soit r√©p√©table
  * ensuite j'ajoute mon test et le changement est easy
  * (ah, maintenant faut que j'ajoute une CI !!)

-v-

## Trop tard

* De toute fa√ßon y'a jamais eu de tests sur ce projet, c'est trop tard ! <!-- .element: class="fragment" -->
* √áa sert √† rien de tester ma feature, le reste est pas test√©, pis √ßa m'a pris tellement de temps ! <!-- .element: class="fragment" -->
* Comment j'injecte mon code de test ? Y'a rien qu'est pr√©vu ! <!-- .element: class="fragment" -->
* Comment je sais ce qui se passe ? Y'a √† peine de logs et on peut se brancher sur rien ! <!-- .element: class="fragment" -->
* Je teste quoi ? Que √ßa marche comme maintenant ? Parce que c'est pas clair ce que √ßa devrait faire ! <!-- .element: class="fragment" -->

Notes:
* JULIEN: anecdote proc√®s

<!--
* descriptivism vs prescriptivism (cf Romeu)
* test de caract√©risation OK, mais est-ce que c'est ce que √ßa devrait vraiment faire ? ü§∑
  * bug ou feature ?
  * xkcd workflow https://xkcd.com/1172/
* source de v√©rit√© = code ou spec Word ?
-->

-v-

## L'enfer !

<style>
  /* D√©finition de la classe pour empiler les images */
  .stacked {
    position: absolute; /* Positionne les images par rapport au parent */
    top: 1000;
    left: 50%; /* Positionne les images √† 50% de la largeur de la page */
    transform: translateX(-50%); /* Ajuste la position pour que l'image soit centr√©e */
    width: auto;
    height: auto; /* Laisse la hauteur s'ajuster selon les proportions naturelles */
    z-index: 1; /* D√©finit l'ordre d'affichage des images */
  }

  /* Animation pour faire appara√Ætre chaque image progressivement */
  .stacked.fragment {
    z-index: 10; /* Chaque fragment aura un index plus √©lev√© que le pr√©c√©dent */
    animation: fadeIn 1s forwards; /* Animation de fade-in pour l'apparition des images */
  }

  /* D√©finition de l'animation fade-in */
  @keyframes fadeIn {
    from {
      opacity: 0;  /* L'image commence avec une opacit√© de 0 (invisible) */
    }
    to {
      opacity: 1;  /* L'image termine avec une opacit√© de 1 (visible) */
    }
  }
</style>

Trop difficile de savoir quoi faire, comment faire, de le faire, √† ex√©cuter, √† analyser,
√† maintenir, √† faire confiance, pas assez, pas assez bien, pas assez rapide...

On test en prod alors ???  <!-- .element: class="fragment" -->

![](./test-in-prod5.jpeg)  <!-- .element: class="fragment stacked" -->
![](./test-in-prod2.jpeg)  <!-- .element: class="fragment stacked" -->
![](./test-in-prod7.jpeg)  <!-- .element: class="fragment stacked" -->
![](./test-in-prod.png)  <!-- .element: class="fragment stacked" -->
![](./test-in-prod6.jpeg)  <!-- .element: class="fragment stacked" -->
![](./test-in-prod3.jpeg)  <!-- .element: class="fragment stacked" -->
![](./test-in-prod4.jpeg)  <!-- .element: class="fragment stacked" -->

Notes:
* difficile de savoir quoi faire, comment faire, de le faire, √† ex√©cuter, √† analyser, √† maintenir, √† faire confiance, pas assez, pas assez bien, pas assez rapide, ...
* Facile √† dire de faire "le bon test", mais concr√®tement ?
  * y'a le bon testeur et le mauvais testeur ...
* transition

---

# Trouver la Voie

Comment faire pour bien tester auto ? Il faut s'aider !

Notes:
* TODO:
  * @julien √† chaque section mettre un exemple + anecdote !!!
* TODO : exemples de test
  * fonction pure (mais avec de la complexit√© interne), quelques cas d'erreur pr√©vus -> tests fonc, table, edge cases, fuzz, property-based
  * fonction qui lit un fichier
  * fonction qui tape une API web : mock, contrat, VCR, fake d'API
  * fonction qui tape une grosse Postgres legacy, nouvelle feature

-v-

<!-- .slide: data-background-image="./Top_Rope_Climbing_5.jpg" -->

Notes:
* m√©taphore du chemin de cr√™te : facile de redescendre, difficile de rester au bon endroit
* TODO: m√©taphore escalade ?
* comment le naviguer ? comment √™tre/devenir/rester rigoureux ?
  * discipline d'un moine bouddhiste, ou d'un garde de la reine d'Angleterre

-v-

## Culture de la qualit√©

> Culture eats strategy for breakfast. -- Peter Drucker (apocryphe !!)

* Il faut avant tout changer la culture de l'organisation / de l'√©quipe <!-- .element: class="fragment" -->
  * implication de toutes les parties prenantes <!-- .element: class="fragment" -->
  * d√©marche commune et adopt√©e, pas juste avoir un casse-pied de service <!-- .element: class="fragment" -->
  * tournure d'esprit requise pour malmener le code ("vicieux") <!-- .element: class="fragment" -->
    * "un testeur rentre dans un bar, il commande ..."
  * humilit√© <!-- .element: class="fragment" -->
  * responsabilit√© individuelle + √©quipe <!-- .element: class="fragment" -->
* Avoir de l'exp√©rience est un vrai plus <!-- .element: class="fragment" -->

-v-

Petit floril√®ge :

> Le test n'apporte pas de valeur (argent) par rapport aux fonctionnalit√©s <!-- .element: class="fragment" -->

> you get paid for "software", not "maintainable software" -- joncroks sur news.ycombinator.com <!-- .element: class="fragment" -->

> Move fast and break things -- Facebook (jusqu'en 2014)  <!-- .element: class="fragment" -->

> I get paid for code that works, not for tests [...] -- Kent Beck (tronqu√© !!)  <!-- .element: class="fragment" -->

Notes:
* culture qualit√©, formation (cours, conf√©rences, livres, exercices, katas, ...)
* cf nos recos √† la fin, exp√©rience (empirisme)
* compr√©hension du business et des stakeholders,
* tournure d'esprit (cf joke "un testeur rentre dans un bar, il commande -1 bi√®re, NaN bi√®re, demande o√π sont les toilettes ..."), "vicieux" pour "casser le code" et non pas seulement montrer qu'il fonctionne
* exemple : SQLite testing, test code ratio, test harnesses, ... (+√©volution dans le temps)
* le code il faut le malmener
* la qualit√© c'est un ensemble de tamis successifs : empilement de couches pour attraper les bugs, du besoin, design, archi, implem, test, validation, d√©ploiement
  * processus/d√©marche au niveau de l'√©quipe/projet/entreprise/...
* exemple : NDP Systems
* "Le test n'apporte pas de valeur (argent) par rapport aux fonctionnalit√©s"
* Humilit√© de devoir tester
* "move fast and break things"
* https://news.ycombinator.com/item?id=13130991 : you get paid for "software", not "maintainable software"
* Avoir un "Patrick" (ou whatever name) dans son √©quipe, √©ternellement vigilant, le "relou"
* comme beaucoup de sujets, c'est pas un casse-pied de service qu'il faut, mais un changement de culture (beaucoup plus compliqu√©, cf Agile bullshit, s√©curit√©, ...)
* Responsabilit√© individuelle et d'√©quipe
* la qualit√© c'est une d√©marche, un tamis, un empilement (vrai sens de Kanban), une culture (LEAN, Kanban "right the first time")
* market cap de Facebook en 2014 >= 140 milliards de $

-v-

## Investissement

> Pas de bras, pas de chocolat ! -- Omar Sy

* Une suite de tests autos est un logiciel, dont le but est de v√©rifier le bon fonctionnement d'un autre <!-- .element: class="fragment" -->
* Il s'agit d'un second syst√®me, qui sert √† stabiliser le premier <!-- .element: class="fragment" -->
  * Il n'apporte pas de valeur directe au client, mais aide le premier √† en apporter (comme la doc, la CI, le marketing...) <!-- .element: class="fragment" -->
* C'est un investissement <!-- .element: class="fragment" -->
  * Il faut des ressources : temps, comp√©tences, hardware, runner de CI, donn√©es...
  * Le meilleur moment pour investir dedans, c'√©tait hier, le second meilleur c'est aujourd'hui <!-- .element: class="fragment" -->
  * Il est d'autant plus rentable qu'on l'utilise (enabler !) <!-- .element: class="fragment" -->
  * Analyse co√ªt-b√©n√©fice, ROI (return on time invested) <!-- .element: class="fragment" -->
* Exemple (extr√™me !) de SQLite : 590x plus de code de test que de code de prod <!-- .element: class="fragment" -->

-v-

![xkcd 974 "The General problem"](./the_general_problem.png) <!-- .element: class="fragment" -->

Notes:
* Pas de spec ...
* Pas le temps ...
* Pas les comp√©tences ...
* Pas les outils ...
* Pas le hardware ...
* Pas les moyens de d√©ployer ...
* Pas de data de test ...
* humains, techniques, temporels, ...
* outils de test, formations, avoir le temps, d√©ployabilit√©, disponibilit√© du hardware, dispo des data, ...
* avoir des specs ! (claires)

-v-

> I find that when someone's taking time to do something right in the present, they're a perfectionist with no ability to prioritize, whereas when someone took time to do something right in the past, they're a master artisan of great foresight.

![xkcd 1205 "Is it worth the time?"](./is_it_worth_the_time.png)  <!-- .element: class="fragment" -->

Notes:
* investissement dans un second logiciel pour mieux produire le premier
* outils de test
* investir dans le futur
* projet logiciel = le code qui part en prod, mais pas seulement, aussi : la doc, la CI, les specs, et donc aussi les tests, ...
* "Le test n'apporte pas de valeur (argent) par rapport aux fonctionnalit√©s" (et les fonctionnalit√©s non plus d'ailleurs, √ßa d√©pend si elles sont connues, utilis√©es, ...)
* Second-syst√®me de stabilisation du premier, par opposition √† la flexibilit√©
* Une s√©curit√©, ou un frein ? les deux ?
* exemple de SQLite (x 590)
* Vraiment √† retenir : ne pas penser le test comme un apr√®s, mais comme un m√™me temps, voire enabler
* estimer le ROI de l'automatisation : gain versus co√ªt ? matrice
  * c'est un gros sujet pour les Test Managers, et les chefs de projets
* le meilleur moment pour commencer √† mettre des tests sur le projet c'√©tait le premier jour, le second meilleur moment c'est aujourd'hui
* https://xkcd.com/974/ "The General problem" (et sa caption : perception de perfectionniste versus ma√Ætre-artisan)
* https://xkcd.com/1205/ "Is it worth the time?"
* Le code pourrit sans test auto, mais les tests auto eux-m√™mes pourrissent, ou peuvent pourrir (v√©rouiller) le code
* J'avais un probl√®me, maintenant j'en ai deux (un nouveau)
* le test c'est une analyse co√ªt-b√©n√©fice : combien je veux mettre dans mes tests, pour le run de mon dev et de ma prod
* des tests syst√®mes pas effectu√©s = risque business
  * exemples : 8 bcs biologic, 50 bornes schneider, ...

-v-

## Strat√©gie de test

* Premi√®re question : POURQUOI je teste ? Qu'est-que je veux obtenir ?  <!-- .element: class="fragment" -->
* Exemple de raisons de tester : <!-- .element: class="fragment" -->
  * Garantir la qualit√© <!-- .element: class="fragment" -->
  * Eviter les r√©gressions <!-- .element: class="fragment" -->
  * Valider les sp√©cifications/exigences <!-- .element: class="fragment" -->
  * Se rassurer <!-- .element: class="fragment" -->
  * Apprendre √† tester, essayer le TDD <!-- .element: class="fragment" -->
  * Diluer les responsabilit√©s <!-- .element: class="fragment" -->
  * Cocher une case <!-- .element: class="fragment" -->
* Deuxi√®me question : quelles sont mes contraintes et mes ressources ? <!-- .element: class="fragment" -->
* Troisi√®me question : quel est mon p√©rim√®tre ? Qu'est-ce qui d√©pend de moi ou pas ? <!-- .element: class="fragment" -->
* Quatri√®me question : dans mon p√©rim√®tre, comment puis-je le d√©couper ? <!-- .element: class="fragment" -->

-v-

## Strat√©gie de test 2

* Maintenant on peut d√©finir quel code on va tester, et jusqu'o√π <!-- .element: class="fragment" -->
  * Souvent on tombe sur une pyramide, des tamis successifs pour attraper les bugs  <!-- .element: class="fragment" -->
    * plein de petits tests de fonctions, quelques tests de l'ensemble  <!-- .element: class="fragment" -->
    * du besoin √† la prod, et toutes les √©tapes interm√©diaires  <!-- .element: class="fragment" -->
* Une strat√©gie √† √©crire ! <!-- .element: class="fragment" -->
* Une strat√©gie √† faire √©voluer au fur et √† mesure ! <!-- .element: class="fragment" -->
* La suite de test est un sous-projet en soi, √† consid√©rer en tant que tel.<!-- .element: class="fragment" -->

![](Perceval.jpg)  <!-- .element: class="fragment" -->

Notes:
* quoi pourquoi pour quoi comment qui quand ...
* sp√©cifications, Exigences et Requirements, business (value stream) et risques business, quadrants, matrice confiance versus risque, moyens (et toute la suite)
  * cartographier les flux d‚Äôinformation, les cas d‚Äôusage, les fronti√®res techniques et les domaines de l‚Äôapplication afin de discerner les fronti√®res des tests
* construisez votre "pyramide" (demander √† une IA diff√©rente pyramides, de plein de formes diff√©rentes √† la Dali), en se basant sur les moyens de test
* √† adapter/repenser r√©guli√®rement, comme tout le reste
* pourquoi, pour quoi, quoi, o√π, qui, quand et comment, ...
* trust boundaries (d√©pendences externes, parties peu fiables, risque m√©tier, responsabilit√©, vitesse d'√©volution, ...)
* Repenser la strat fr√©quemment, tout comme on le fait pour l'architecture de la solution
* consid√©rer les niveaux de test : Fonctionnalit√©s techniques (endpoint) versus user
* Quadrant des tests !! Axes : business vs tech, pour le produit vs √®quipe
* d√©pendences externes (on ne les controle pas, c'est compliqu√©, et elles peuvent changer sans qu'on y pr√™te attention) versus d√©pendances internes (on les controle, mais c'est quand m√™me compliqu√©, et peuvent changer si on ne fait pas assez gaffe)
* Choisir l'effort de test par p√©rim√®tre = choisir l√† o√π on pr√©f√®re diminuer la proba d'un bug
* contrats (boundaries)
* Plan de test au format IEEE 29119-3 (ou pas !)
* Le syst√®me test√© peut faire partie d'un sur-syst√®me, et se composer de sous-syst√®mes, les composants des uns sont les acceptation des autres
  * Ce qui d√©pend de nous versus ce qui ne d√®pend pas (sto√Øcisme)

-v-

## Renoncer

> Choisir, c'est renoncer -- citation d'Andr√© Gide (d√©form√©e)

* Impossible de tout tester, tester c'est choisir <!-- .element: class="fragment" -->
  * Impossible de tester toutes les entr√©es possibles <!-- .element: class="fragment" -->
  * Impossible de tester tous les chemins d'ex√©cution   <!-- .element: class="fragment" -->
  * Pas forc√©ment pertinent de viser les 100% de couverture <!-- .element: class="fragment" -->
  * Pas toujours pertinent d'automatiser : trop compliqu√©, trop cher... <!-- .element: class="fragment" -->
    * Il faut alors pr√©voir une proc√©dure de tests manuels !
* Mettre les efforts sur les parties critiques <!-- .element: class="fragment" -->
* Tenir compte du retour d'exp√©rience (qu'est-ce qui a buggu√© m√©chamment ?) <!-- .element: class="fragment" -->
* On peut supprimer des tests : pas fiables, trop lents, redondants... <!-- .element: class="fragment" -->
* On doit refactorer ses tests, leur faire suivre la croissance du logiciel <!-- .element: class="fragment" -->

Notes:
* renoncer √† tout automatiser (quadrants, moyens insuffisants, ...), ROI
* tradeof : cout, risque, complexit√©, ...
* crit√®re qui favorisent l'automatisation : r√©p√©tition, confiance dans l'autom, p√©nibilit√©, longueur, criticit√©, ...
* il vaut mieux un mix d'autom et de manuel, la force de chacun
* Le co√ªt des tests est parfois sup√©rieur aux ben√©fices
* exemple : lecteur de fichier √† EDF
* Tester le code techniquement complexe, sensible pour le m√©tier, et utile
* loi de pareto 80/20 : toujours fausse, toujours vraie
* hybrid possible aussi (soit manuel assist√© par autom, soit autom avec verif manuelle) : continuum Automatis√©-automatisable-manuel
* Sans jugement : un pas apr√®s l'autre, on h√©rite de codebases, on essaye de faire mieux
  * incr√©mental
* tester ne prouve pas l'absence de bugs, mais en √©limine certains
* process avec des rendements d√©croissants, trouver le bon curseur, le bon √©quilibre
* garder des tests qu'on appr√©cie : rapides (ou moins rapides en CI mais + couvrants), fiables, maintenables, estimer le ROI
* OK de supprimer un test inutile
* fatalisme, tout tester en auto est un voeu pieux
* Choisir ses batailles, mettre les efforts au "bon" endroit
* √† tester = risque business + risque tech + facilement automatisable >= 1

-v-

## Sc√©narios

* On sait pourquoi on teste, ce qu'on teste, et avec quel moyens. Quels tests alors ?
  * Test globaux <!-- .element: class="fragment" -->
    * Exemple : Cas d'usage utilisateur, test end-to-end
    * Test de l'ensemble du syst√®me, √† partir de son interface utilisateur
    * üòá Assez court √† √©crire, test beaucoup de code d'un coup
    * üòà Tend √† √™tre fragile, √† ne tester que le chemin d'ex√©cution attendu
  * Tests de function <!-- .element: class="fragment" -->
    * Appel une fonction/m√©thode et v√©rifie sa sortie
    * Le plus souvent isol√© du reste du syst√®me en coupant les effets de bords
      * Id√©al pour les fonctions sans effet de bord (maths...)
    * üòá Sp√©cifique, facile √† garder en t√™te, ind√©pendant
    * üòà Beaucoup de tests √† √©crire, peut ne pas tester grand chose
  * Tout le reste entre les deux ! <!-- .element: class="fragment" -->
  * Une feature = un test ?  <!-- .element: class="fragment" -->
  * D√©pend de ses objectifs, ses moyens, son exp√©rience...  <!-- .element: class="fragment" -->
      * Juste v√©rifier que le code compile et s'ex√©cute ?
      * D√©cliner les spec ? (top-down)
      * Ajouter un test √† chaque bug ? (bottom-up)

Notes:
* sc√©narios de test (nominaux, critiques, ...) d√©cid√©s, "use cases" (orient√©s "utilisateur" de l'interface)
* TODO retravailler cette section, semble un peu redite avec la strat√©gie
* typologie de test : "unitaire au niveau technique (m√©thode/classe)", ou "unitaire d'interface mais profond"
* avoir une spec
  * Exigences et Requirements (cf Schneider, Thales, ...)
* value streams, risques, manque de confiance, ...
* smoke tests (cf origine du mot "smoke test" en logiciel)
* quoi tester ? critique ou sujet √† forte r√©gression, et stable, fr√©quence d'ex√©cution
* (reprendre des tamis) : tres amigos, example mapping, BDD, prise en compte de la testabilit√© d√®s la (pr√©-)conception, compter le co√ªt du test dans l'estimation de la story, les tests font partie de la dette technique du projet, analyse d'impact lors de nouveaux devs, d√©coupage en √©quipe Dev versus QA ??
  * identifier les manquements dans son √©quipe, sur son projet, et trouver comment communiquer dessus avec les autres, avoir des id√©es √† proposer

-v-

## Architecture testable

* si ce n'est pas un objectif, alors ce sera n√©glig√©
* si le code n'est pas facilement testable, alors les tests seront difficiles   <!-- .element: class="fragment" -->
* bien d√©finir les interfaces et contrat (cf juste apr√®s)   <!-- .element: class="fragment" -->
* identifier les "seams" (couture, lignes de faille, ...)   <!-- .element: class="fragment" -->
* privil√©gier les fonctions "pures" (sans effets de bord) quand c'est possible   <!-- .element: class="fragment" -->
  * "functional core, imperative shell"
  * limiter la mutabilit√©
* choisir quand limiter le couplage   <!-- .element: class="fragment" -->
  * inversion de d√©pendance

Notes:
* sinon architecture intestable ou semi-testable
* seams (cf Michale feathers, Working effectively with legacy code) versus scalpel et pied-de-biche
* d√©pendances, interfaces, contrats, ... "trust boundaries"
* you can't write good tests for badly written code
* version de dev, suffisament isoprod mais avec des backdoors
* attention au couplage : ni trop peu, ni pas assez (monolithe spaghetti versus micro-services passe-plats)
  * plus simple de tester des fonctions (niveau code) que des programmes
* functionnal core, imperative shell (ou h√©xagonal, ou onion)
* pousser les IO √† l'ext√©rieur (technique du sandwich)
* design goal sinon accidentel
* crit√®re d'acceptabilit√©
* state is the enemy, prog fonctionnelle
* narrow interfaces for deep modules
* "fracture planes" de Team Topo, selon des "lignes de faille" (user persona, tech, change cadence, regulatory compliance, team location, risk, performance isolation, ...)
  * cf https://teamtopologies.com/key-concepts-content/finding-good-stream-boundaries-with-independent-service-heuristics
  * cf https://yoan-thirion.gitbook.io/knowledge-base/xtrem-reading/resources/book-notes/team-topologies#software-boundaries-or-fracture-planes
* sans architecture testable, la strat s'effondre !
* introduire des interfaces au bon endroit pour casser la combinatoire (passer de la multiplicaton des cas √† l'addition)

-v-

## Surface d'interface

> good cut point has narrow interface with rest of system: small number of functions or abstractions that hide complexity demon internally, like trapped in crystal
> -- grugbrain.dev

* interface = surface de contact entre deux syst√®mes <!-- .element: class="fragment" -->
  * les m√©thodes publiques d'une classe, les fonctions d'un module, leurs types et exceptions
* interface = abstraction <!-- .element: class="fragment" -->
* tout est une API <!-- .element: class="fragment" -->
* surface large = trop de choses √† tester <!-- .element: class="fragment" -->
  * garder le minimum (SRP)
  * (complique le refactoring)
  * la profondeur c'est OK
* tester l'interface, pas l'impl√©mentation <!-- .element: class="fragment" -->
  * contravariance des tests (refactoring !)

Notes:
* un crit√®re primordial pour faciliter la testabilit√© : ma√Ætriser la surface (de test) du code
* Tester aux fronti√®res d'une interface, que ce soit une m√©thode priv√©e, publique, classe, module, programme, sous-syst√®me, syst√®me, sur-systeme
* facile pour des modules narrow-interface mais deep, impossible pour des hubs
* les "unit" tests n'ont pas vocation √† tester le moinds de lignes possible, mais √† tester des APIs
* Ne pas tester tout le code ? Cf couverture, et faire des tests crois√©s
* Quantit√© de test versus qualit√©
* contravariance, tester l'interface plut√¥t que l'impl√©mentation, cf Uncle Bob https://blog.cleancoder.com/uncle-bob/2017/10/03/TestContravariance.html
* bon test = SRP + behavior not implementation
* niveau de test :
  * Test u = contrat dev
  * Test int√© = contrat int√©grateur
  * Test accep = contrat user
* Exercer le syst√®me depuis l'ext√©rieur
  * ok pour du e2e
  * un d√©sastre pour en tester des sous-parties (banane, gorille, jungle)
* "mock roles, not objects" - in "Growing Object-Oriented Software, Guided by Tests" by Steve Freeman and Nat Pryce

-v-

## Feedback

* les tests sont les premiers utilisateurs de notre code
  * du code peu testable se voit imm√©diatement ! et √ßa se propage !
* A la fin du dev, il est parfois trop TARD pour corriger le tir : Shift Left <!-- .element: class="fragment" -->
  * il fallait le prendre en compte lors de l'impl√©mentation, du design, du poker, de la story ...
* A la fin du dev, il est parfois trop TOT pour corriger le tir : Shift Right <!-- .element: class="fragment" -->
  * √ßa part en prod en on surveille (feature toggle, monitoring, metrics)
  * (beaucoup plus s√©rieux que dire "je teste en prod")
* le test est une consid√©ration tout du long du process : TestOps, Full Cycle <!-- .element: class="fragment" -->
  * √©viter la loi de Conway : les testeurs testent, les autres s'en fichent
* le bon test : il ne passe tout le temps ni n'√©choue tout le temps, il √©choue pour les bonnes raisons  <!-- .element: class="fragment" -->
  * le bon chasseur ...



Notes:
* un test qui p√®te, c'est une bonne nouvelle : un bug de moins en prod !
* les bugs viennent aussi de la code review, la spec, le process, les communications...
* les bugs ne sont pas que des erreurs mais aussi des occasions d'am√©liorer
  * (beaucoup plus s√©rieux que dire "c'est pas un bug mais une feature")
* un signal (au sens de la "th√©orie de l'information")
* fast feedback + CI/CD + DevOps (monitoring, observability), frequent deployment, Monitoring, debuggability (shift right)
* Feedback lors du dev, test, code review, design, recette, bugs en prod : tout renseigne sur ce qui m√©rite d'√™tre test√© et comment (shift left)
* tester en prod avec le devops : canary, green-blue, ...
* Les tests doivent planter de temps en temps, pour les bonnes raisons
  * Signal et feedback
  * Doivent ne pas √©chouer tout le temps (sinon signe de couplage) ni jamais (signe que rien n'est test√©). Doivent √™tre un signal, ni z√©ro ni un. √âquilibre difficile.
* Les tests qui p√®tent (pour une bonne raison) c'est moins de bugs en prod, qui est l'objectif principal.
* luter contre la "loi de conway" : les devs versus les testeurs, cf Full Cycle
* pas de "√ßa marche sur ma machine"
* du code difficile √† tester va engendrer + de tests fragiles, sans am√©liorer le design, qui va empirer, et ainsi de suite

-v-

## Rester fluide

> Docteur, quand j'appuie l√†, j'ai mal !
> Alors n'appuyez pas l√†.
> -- blague

> If it hurts, do it more often.
> -- core XP principle

* Pente glissante de la qualit√© üòà <!-- .element: class="fragment" -->
  * Si les tests sont difficiles √† lancer, ils le seront de moins en moins  <!-- .element: class="fragment" -->
  * Si les tests ne sont pas fiables, ils seront de moins en moins regard√©s  <!-- .element: class="fragment" -->
  * Si les tests sont lents, la suite de test sera de plus en plus lente <!-- .element: class="fragment" -->
* Identifier les "pain points" et les r√©soudre üòá  <!-- .element: class="fragment" -->
  * ajouter un test doit √™tre simple et rapide
  * lancer les tests doit √™tre simple et rapide

-v-

## Acc√©l√©rer ses tests ?

* Tests trop lents (~15 min), alors refactorisation de la suite de test üòá <!-- .element: class="fragment" -->
  * Parall√©lisme ?
  * Optimisation des tests lents ?
  * S√©paration en 2 suites, une rapide et une compl√®te ?
  * Framework de test plus √©volu√© ?
  * Lancement s√©lectif des tests selon les fichiers modifi√©s ?
* Corollaire : √©viter (autant que possible) üòà  <!-- .element: class="fragment" -->
  * les micro-services
  * les submodules
  * les tests dans un repo √† part
  * ...

Notes:
* ne pas √™tre capable de r√©aliser les tests rapidement diminue l'it√©rativit√©, la qualit√©, l'agr√©abilit√©, ... la probabilit√© qu'ils soient √©crit tout court
  * comme un √©vier plein de vaisselle (cercle vicieux)

-v-


## Ecriture

Quelques r√®gles d'√©criture pour les tests :

* setup et teardown pour pr√©parer/d√©comissionner les ressources n√©cessaires <!-- .element: class="fragment" -->
* structure du test en Arrange-Act-Assert ou Given-When-Then <!-- .element: class="fragment" -->
* au moins un assert par test <!-- .element: class="fragment" -->
* tenter de tester une seule chose par test plut√¥t qu'une suite de stimuli <!-- .element: class="fragment" -->
* FIRST = Fast, Independant, Repeatable, Self-Checking, Timely <!-- .element: class="fragment" -->
* diff√©rencier "erreur" (plantage, pas de r√©sultat de test) versus "√©chec" (r√©sultat n√©gatif) <!-- .element: class="fragment" -->

Notes:
* m√©thodologie d'√©criture : setup/teardown, Given/When/Then, Assert/Arrange/Act, tester une seule chose plut√¥t qu'un sc√©nario complet, erreur versus √©chec
* FIRST : https://stackoverflow.com/questions/18024785/tdd-first-principle Fast Indep Repeat Self-Check Timely (pas √©crit dans 1000 ans mais avec le code √† tester)
  * double i : isolation ?
  * test FIRST : Timely ou Thorough ?
* un test sans assert = red flag
* unit test = focus, sinon sc√©nario utilisateur end-to-end
  * sinon "Shotgun unit testing" : le test fait tout et n'importe quoi

-v-

## Techniques

Le minimum √† ma√Ætriser selon nous :

* la mise en place de son environnement de test, en local et en CI <!-- .element: class="fragment" -->
  * peut √™tre tr√®s simple avec certains projet, moins pour d'autres
* le framework de test standard de son langage <!-- .element: class="fragment" -->
  * vous n'√™tes pas seuls avec vos probl√®mes de tests üòá
* les techniques d'isolation des effets de bord : fakes, mocks, TestContainers... <!-- .element: class="fragment" -->
* les techniques de lisibilit√© et de factorisation des tests <!-- .element: class="fragment" -->

Notes:
* ce qu'on consid√®re le minimum √† ma√Ætriser pour tester
* test harness
* TestContainers
* framework
* mocking et fakes versus simulateurs/√©mulateurs, oracles
  * qu'est-ce je gagne et je perds si je mocke ? gain = vitesse d'exec + facile √† mettre en oeuvre (autospec), perte = maintenabilit√© et r√©alisme
* DB in-memory

-v-

## Techniques avanc√©es

* IA pour les tests <!-- .element: class="fragment" -->
* couverture de test  <!-- .element: class="fragment" -->
* snapshot testing  <!-- .element: class="fragment" -->
* fuzzing  <!-- .element: class="fragment" -->
* tests d'architecture  <!-- .element: class="fragment" -->
* tests de performance et de charge  <!-- .element: class="fragment" -->
* Page Object Model (POM) pour les tests d'UI  <!-- .element: class="fragment" -->
* Accelerate <!-- .element: class="fragment" -->
* ...   <!-- .element: class="fragment" -->

Juste le sommet de l'iceberg ! <!-- .element: class="fragment" -->


(le reste en annexe et dans les sources des slides)  <!-- .element: class="fragment" -->

Notes:
* pour aller + loin (et qui m√©rite chacun son 45 minutes ou +) pour d√©velopper culture et savoir-faire

---

# Conclusion

* Le test est indispensable, l'automatisation (partielle) aussi <!-- .element: class="fragment" -->
* Le test n'est pas simple, il faut l'apprendre et acqu√©rir de l'expertise <!-- .element: class="fragment" -->
* Il faut l'initier, construire du consensus quand on n'est que dev <!-- .element: class="fragment" -->
* Le test fait partie int√©grante de l'ing√©nierie logicielle <!-- .element: class="fragment" -->

Notes:
* expertise indispensable, il faut s'y mettre, dans un environnement semi-hostile (vocab, √©quipe, rythme, outillage, ...) -> CI, run local. C'est une partie de l'ing√©nierie

---

# Nos recommandations

* Titus Winters, Tom Manschrek et Hyrum Wright - Software Engineering at Google ([online](https://abseil.io/resources/swe-book))
* Michael feathers - Working effectively with legacy code
* [BiteCode - Testing with Python (part 4): why and what to test?](https://www.bitecode.dev/p/testing-with-python-part-4-why-and)
* [Dwayne Richard Hipp - How SQLite Is Tested](https://www.sqlite.org/testing.html)
* [Adam Bender - SMURF: Beyond the Test Pyramid](https://testing.googleblog.com/2024/10/smurf-beyond-test-pyramid.html)
* [Mi≈°ko Hevery - Writing Testable Code](https://testing.googleblog.com/2008/08/by-miko-hevery-so-you-decided-to.html)
* [Jeremy Sorent - J'√©cris de tests sans pleurer maintenant](https://www.youtube.com/watch?v=2S9TxoTE8BA)
* [Gary Bernhardt - Boundaries](https://www.destroyallsoftware.com/talks/boundaries)
* ... et 27 autres en annexe !

Notes:
* Avis de Julien, pourquoi recommander :
  * Jeremy Sorent - J'√©cris de tests sans pleurer maintenant
    * un talk assez similaire √† celui-ci dans l'intention, mais recentr√© sur le design du code
  * Michael feathers - Working effectively with legacy code
    * √ßa parle beaucoup beaucoup de test, et surtout de comment reprendre le contr√¥le une fois que √ßa a d√©rap√© !
  * Dwayne Richard Hipp - How SQLite Is Tested
    * un exemple de comment n'avoir quasi aucun bug pour un des logiciels les plus utilis√© au monde
  * Adam Bender - SMURF: Beyond the Test Pyramid
    * un exemple par Google de d√©tricoter la pyramide des tests dans une vision compl√©mentaire des tests selon leurs propri√©t√©s techniques
  * Mi≈°ko Hevery - Writing Testable Code
    * un ensemble de bons conseils pour rendre son code testable, dont le premier point ("Mixing object graph construction with application logic") est trop m√©connu
  * BiteCode - Testing with Python (part 4): why and what to test?
    * pas si sp√©cifique √† Python, toute la s√©rie d'articles vaut le d√©tour, mais cet √©pisode s'attarde sur, sans le nommer ainsi, la strat√©gie de test
  * Gary Bernhardt - Boundaries
    * comment d√©couper son application pour faciliter sa testabilit√© (notion de "context domain" du DDD)
  * Titus Winters, Tom Manschrek et Hyrum Wright - Software Engineering at Google
    * de tr√®s bonne qualit√©, et parle significativement de test

---

# Cr√©dits photos

* [m√®me de source inconnue, sur yaplakal.com](https://s00.yaplakal.com/pics/pics_preview/4/4/7/10845744.jpg)
* [image de voie d'escalade, sur Wikimedia](https://commons.wikimedia.org/wiki/File:Top_Rope_Climbing_5.jpg)
* [m√®mes de "test en prod", via Google Images](https://www.google.com/search?udm=2&q=test+en+prod)

---

# Remerciements

* Damien Roulier
* Eric Papazian
* Mathieu Mattringe
* Rachel Da Silva
* Francky Flamant
* Fanny Velsin
* Victor Lambret

---

# Questions

Slides : [https://github.com/Lenormju/talk-enfer-test-autos/](https://github.com/Lenormju/talk-enfer-test-autos/)

Notes:
* TODO QRcode vers les slides : https://github.com/Lenormju/talk-enfer-test-autos/

---

# Plus de recommandations !!

* [Joel "on Software" Spolsky - Hard-assed Bug Fixin‚Äô](https://www.joelonsoftware.com/2001/07/31/hard-assed-bug-fixin/) : est-ce que tous les bugs devraient √™tre corrig√©s ? √ßa d√©pend.
* [Mathieu Eveillard - 50 shades of tests](https://www.mathieueveillard.com/blog/50-shades-of-tests) : des d√©finitions plut√¥t claires pour diff√©rents types de test, leur positionnement sur 3 dimensions, au-del√† de la pyramide de tests
* [Marc Hage Chahine (La Taverne du Testeur) - Que doit-on attendre d‚Äôun testeur ?](https://latavernedutesteur.fr/2025/09/15/que-doit-on-attendre-dun-testeur/) : les diff√©rentes dimensions du m√©tier de testeur
* [Arnaud Lemaire - From code to consequences](https://www.youtube.com/watch?v=muRdH9u7gO4) : en quoi les "full cycle engineers" sont importants pour mener √† bien des projets
* [Colin Damon - Ma typologie de tests et leur √©quilibrage](https://www.linkedin.com/posts/colin-damon_mettre-en-place-une-strat%C3%A9gie-de-tests-qui-activity-7343525861444247552-6BJY) : un exemple de "pyramide" dans un contexte pr√©cis
* [Redowan Delowar - Test state, not interactions](http://rednafi.com/go/test-state-not-interactions/) : pourquoi les tests propos√©s par des LLMs ne sont pas n√©cessairement les bons, et comment faire mieux (par exemple privil√©gier les fakes aux mocks)
* [Jeff Atwood (CodingHorror) - Falling Into The Pit of Success](https://blog.codinghorror.com/falling-into-the-pit-of-success/) : comment ne plus avoir besoin de se battre pour que la qualit√© ne d√©gringole pas ?

-v-

* [Antoine Mazure - Tests pragmatiques : comment presque arreÃÇter les tests automatiseÃÅs ?](https://www.youtube.com/watch?app=desktop&v=ohV6GvCIeLY) : un exemple de tester la mauvaise chose, et de comment mieux tester avec pourtant moins de tests
* [Jules Poissonnet et Antoine Caron - Tester c'est tricher)](https://www.youtube.com/watch?v=I_zNxGqRI3w) : une vision d'ensemble, claire et illustr√©e, de la d√©marche de test, du vocabulaire et des difficult√©s
* [Christophe Br√©heret-Girardin - Comment une architecture influence votre strat√©gie de test ?](https://m.youtube.com/watch?v=IeOa6XWxkxg)
* [Ham Vocke - The Practical Test Pyramid](https://martinfowler.com/articles/practical-test-pyramid.html) : des exemples concrets dans un contexte clair de diff√©rents types de test, et des limitations de la pyramide de Mike Cohn
* [Martin Fowler - Mocks Aren't Stubs](https://martinfowler.com/articles/mocksArentStubs.html) : d√©finitions claires de tous les "*test doubles*" (dummy, stub, fake, spy, mock) par Martin Fowler
  * [Martin Fowler - Test Double](https://martinfowler.com/bliki/TestDouble.html) : en version ultra-abr√©g√©e
* [Ana√´l Lefebvre - Comment en finir avec la fragilit√© des tests unitaires](https://www.sqli.com/fr-fr/insights/comment-en-finir-avec-la-fragilite-des-tests-unitaires) : un contexte clair, une explication de FIRST, et une m√©thodo ("ZOMBIES") pour identifier les cas de test
* [The Grug Brained Developer - Testing](https://grugbrain.dev/#grug-on-testing) : des conseils de programmation pertinents, mais r√©dig√©s par "Grug" qui a une capacit√© limit√©e, et qui le revendique (!)

-v-

* [Qalisty et Ana√Øs Fournier - Comment s‚Äôen sortir lorsqu‚Äôon est 1 testeuse face √† 25 d√©veloppeurs ?](https://open.spotify.com/episode/1nwA9nLdezVk6mzWu39T7a) : des techniques concr√®tes pour mettre en place une culture qualit√© et une strat√©gie
* [Victor Lambret - Le TDD sans commencer par les tests](https://www.youtube.com/watch?v=Ddarw3wUXQY) : comme d'habitude avec Victor, un avis mesur√© et avant tout sourc√©, sur le pragmatisme √† conserver face aux techniques TDD/TestFirst/TestAfter
* [Mike Wacker - Just Say No to More End-to-End Tests](https://testing.googleblog.com/2015/04/just-say-no-to-more-end-to-end-tests.html) : les tests unitaires seraient ceux qui compte le plus, du point de vue des utilisateurs (?!), car ce sont eux qui trouvent efficacement les bugs
* [Simon Stewart - Test Sizes](https://testing.googleblog.com/2010/12/test-sizes.html) : caract√©risation des tests (en un tableau), non pas en unitaires versus end-to-end, mais en small versus big, en fonction de leurs IO
* [Igor Roztropi≈Ñski - Unit, Integration, E2E, Contract, X tests: what should we focus on?](https://binaryigor.com/unit-integration-e2e-contract-x-tests-what-should-we-focus-on.html) : de l'int√©r√™t de favoriser les tests d'int√©gration ("in-between", n'√©tant pas extr√™mes), et les tests de contrat
* [Kent C. Dodds - Write tests. Not too many. Mostly integration.](https://kentcdodds.com/blog/write-tests) : introduit la pyramide "trophy" (en incluant les tests statiques) pour des applis JS, avec surtout des tests d'int√©gration
* [Seb Rose - Making a meal of architectural alignment and the test-induced-design-damage fallacy](https://claysnow.co.uk/architectural-alignment-and-test-induced-design-damage-fallacy/) : une bonne le√ßon d'√©quilibre et de pragmatisme

-v-

* [IFTTD #43.src - Test: Tester c'est douter avec Arnaud Lemaire](https://open.spotify.com/episode/2gRex0ajRA1oVc7DZBL0B9) : TODO @Julien
* [C√©cilia Bossard et Angi Guyard - On n‚Äôaurait pas oubli√© un truc dans le craft !?](https://www.youtube.com/watch?v=yVmKkRH60VI) : spoiler il s'agit des tests utilisateurs
* [Gary Bernhardt - Fast Test, Slow Test](https://www.youtube.com/watch?v=RAxiiRPHS9k) : comment choisir entre des tests rapides et des tests lents, en fonction du feedback qu'ils donnent
* [Brandon Rhodes - The Clean Architecture in Python](https://www.youtube.com/watch?v=DJtef410XaM) : √† quels probl√®mes elle r√©pond et comment la mettre en place
* [J.B. Rainsberger - Integrated Tests Are A Scam](https://www.youtube.com/watch?v=fhFa4tkFUFw) : une vision tr√®s centr√©e sur les tests de contrat, pour pousser les "tests d'int√©gration" √† ne porter que sur l'anneau externe de l'application, en interaction avec son environnement (runtime, d√©pendances externes, ...), tout le reste est couvert par du test "unitaire" de contrat + des mocks de collaborateurs

---

# Plus de techniques avanc√©es !

### Types de test

* TU : D√©finition de test unitaire contre-intuitive : ne pas penser microscopique/indivisible, mais coh√©rence/s√©paration-fronti√®re
  * 3 axes : v√©rification de la valeur de retour, v√©rification de l'√©tat, v√©rification de la collaboration
* ATDD versus BDD (parcours versus comportement segment√©, cf la Taverne)
* BDD mindset versus BDD juste au niveau outil
* snapshot/golden-master/approval
  * normatif versus descriptif
  * Approval Testing == Snapshot Testing == Golden Master ?
* en prod : canary release, alpha testing, beta testing, blue-green, Field testing, ...
* user acceptance
* security testing (exemple : [ZAP Proxy](https://www.zaproxy.org/), scanners)
* smoke test / sanity test

-v-

### Types de test

* test de perf
  * rendu accessible par de l'outillage, mais reste rare et hyper-sp√©cifique en terme de sc√©nario
  * typologie selon https://grafana.com/load-testing/types-of-load-testing/ : smoke, average load, stress, soak, breakpoint, spike, ...
* full simulation (√† la Matrix)
  * [What's the big deal about Deterministic Simulation Testing?](https://notes.eatonphil.com/2024-08-20-deterministic-simulation-testing.html)
  * [Pierre Zemb : Et si on faisait du simulation-driven development ?](https://www.youtube.com/watch?v=12LO_l90vDk)
* contract testing
  * Test d'interface d'une third-party (comportement fid√®le aux attentes, rupture d'API, ...), un d'un composant interne √† un autre
* property-based testing + fuzzing
  * property vs fuzzing (cf [article sur la diff√©rence](https://www.tedinski.com/2018/12/11/fuzzing-and-property-testing.html))
  * oracle parfois difficile √† obtenir, parfois √©vident
  * monkey testing (des inputs au hasard, le test n'est pas structur√©, aucun sc√©nario)
* tests de maintenabilit√© ISO 25010 (= modularit√© + r√©utilisabilit√© + analysabilit√© + modifiabilit√© + testabilit√©), cf https://latavernedutesteur.fr/2018/11/19/types-de-tests-iso-25-010-les-tests-de-maintenabilite-7-8/
* test d'accessibilit√©

-v-

### Types de test

* Formal methods, preuves
* [ISO 25010](https://iso25000.com/images/figures/iso_25010_en.png) et [ISO 25019 orient√© usage](https://latavernedutesteur.fr/wp-content/uploads/2023/07/image-1-1024x217.png)
* Black box / white / glass
* tests d'architecture (Java = ArchUnit, Python = PyTestArch)
* tests "statiques" (versus dynamiques) :Linter, typechecker, SonarQube, ... (compilation)
  * des tests qu'il n'y a pas besoin d'√©crire, et qui peuvent s'ex√©cuter sans ex√©cuter le code (statiques)
  * Rust, tooling
* Test d'√©chafaudage (scaffolding): on les met le temps des travaux, puis on les enl√®ve
* test hybride : test auto avec v√©rif humaine, ou test manuel avec assistance autom
* test des logs/metrics (cf [mon post LinkedIn](https://www.linkedin.com/posts/julien-lenormand_est-ce-quil-faut-tester-les-logs-je-suis-activity-7285926322604752896-SC6z))
* London "Mockist"/"Behaviorist" versus Detroit "Classicist"
  * exemple dans un post Linkedin : https://www.linkedin.com/posts/francois-baveye_met-tes-tests-unitaires-%C3%A0-la-poubelle-activity-7370443832401747968-Uc1O
  * tests unitaires : sociables vs solitaires (est-ce que les objets test√©s ont leurs d√©pendances r√©elles ou mock√©es), from "Working Effectively with Unit Tests" de Jay Fields

-v-

### Techniques et outils pour tester

* IA
  * r√¥le de l'IA dans les tests ? (cf [Tao blue/red team](https://mathstodon.xyz/@tao/114915604830689046))
* advanced features of pytest (or your framework) : fixtures, monkeypatch et mocks, plugins
  * know your tools
* mock et doublures : mock/fake/stub/spy (cf Uncle Bob typology)
* chaos testing : chaos monkey + chaos engineering, cf Netflix + [Chaos Monkey Army](https://github.com/Netflix/SimianArmy/wiki/The-Chaos-Monkey-Army)
* fake time (freezegun en Python, libfaketime + LD_PRELOAD), Reactive instead of passive polling ou sleeping
  * exemple : tester du code qui doit s'ex√©cuter pendant des mois (harness de test d'endurance)
* mesure de la couverture de test
  * Code coverage : line/branch/cond
  * 80 ? 90 ? 99 ? Ne suffit pas !!! (exemple : `1 / x` avec x =! 0 et pourtant 100% de coverage, `foo.update()` si foo est null) car il y a des branches "invisibles" (exceptions, donn√©es mal model√©es)
  * test guid√© par la couverture (sans mention de pourcentage), pour orienter les tests
* table testing
* recording/replaying (VCR)

-v-

### Techniques et outils pour tester

* mother object, method factories for test objects, data builders, ... https://martinfowler.com/bliki/ObjectMother.html
* parall√©lisation de tests
* mutation testing : du code de prod, et du code de test, pour mesurer la sensibilit√© et sp√©cificit√© des tests √† la base de code
* boundary analysis et extreme values
* r√®gle du : "0, 1, 2 (many), 9999 (too many), error/exception"
* Page object model (POM)
* Pairwise pour la couverture, en contrant l'explosion combinatoire (produit cart√©sien des param√®tres)
* historisation (visuelle) des r√©sultats, pour rep√©rer les tendances, les patterns
* Technique de refactoring du sandwich (cf Nicolas Carlo √† Alpes Craft 2025) : push IO to the edge (functional core, imperative shell)

-v-

### Techniques et outils pour tester

* systrace/ptrace pour interception et fake des appels syst√®mes (cf libfaketime pour exemple)
* HTTPS Man-in-the-Middle (MITM proxy par exemple) plut√¥t que `ssl_verify=False`
* trucage DNS via `/etc/hosts` ou `/etc/resolv.conf`
* risk-based testing : d√©termination de quels tests ex√©cuter en fonction de la criticit√© de la fonctionnalit√© couverte
* test impact analysis : d√©termination de quels tests ex√©cuter en fonction de quel code a √©t√© modifi√©
* test data management
* anonymiser des donn√©es (de prod)

-v-

### Techniques de design

* TDD (cf on peut pas oublier de les faire √† la fin si on les fait au d√©but), diff√©rents sens du mot TDD, ...
  * cf slides ABC + Discovery Day
  * Mon tddd : testable design
  * "Tdd malgr√® son nom n'est pas une technique de test mais de design"
* [sans-io](https://sans-io.readthedocs.io/)
* architecture h√©xagonale / clean / onion / ...
* programmation fonctionnelle
* profile your tests ! (√©viter les "slips/sleeps sales") cf snakeviz marche aussi pour les tests (cf article de Xavier et son setup de DB), tests en parall√®le (cf article du blog de PyPi), √™tre r√©actif plut√¥t que passif (cf MQTT tester de Schneider)
  * surveiller la performance des tests autos, ne correspond pas aux tests de performance
* trunk-based development + feature flags
* dependency inversion (D de SOLID), SRP
* inclure des fonctionnalit√©s requises par les tests dans le code de prod ? non-pr√©f√©rable mais acceptable

-v-

### Philosophie et process

* Accelerate
  * https://dora.dev/capabilities/ : **test automation + test data management**, but also indirectly code maintainability, documentation quality, job satisfaction, continuous delivery, streamlining change approval, trunk-based development, working in small batches, continuous integration
* DevOps (cf slide)
* Domain-Driven Development (DDD)
* [ISO/IEC 25010:2023](https://www.iso.org/fr/standard/78176.html)
* gestion des erreurs souvent peu pouss√©e, manque de contexte dans les logs
  * error model
* "Clean Test = 3 things : readability, readability, readability" cf Martin Fowler
  * Evolving/surfacing a "testing language" to reveal intent
    * = POM ?

---

# Analyse bibliographique

* Titus Winters, Tom Manschrek et Hyrum Wright - Software Engineering at Google ([online](https://abseil.io/resources/swe-book/html/toc.html))
  * 4 chapitres (sur 34) : Testing overview, Unit Testing, Test Doubles, Larger tests
* Cyrille Martraire, Arnaud Thi√©faine, Dorra Bartaguiz, Fabien Hiegel - Software Craft (1√®re √©dition, 2022, Dunod)
  * 3 chapitres : Tester du legacy, Rendre testable le code legacy, Principes et outils pour tester efficacement
  * 40 pages sur 270
* Robert C. Martin "Uncle Bob" - Clean Code (2008)
  * 1 chapitre et 1 appendice : Unit tests, Testing Multithreaded Code
  * TODO pages sur TODO @Julien
* Len Bass, Paul Clements, Rick Kazman - Software Architecture in practice (3rd edition, 2012)
  * 1 chapitre et 1 sous-chapitre : Testability, Architecture and Testing
  * 22 pages sur 550
* John Ousterhout - A philosophy of software design (edition 2.01, 2020)
  * 2 pages sur 175

-v-

* Michael feathers - Working effectively with legacy code (TODO edition)
  * (recommand√© auparavant)
  * beaucoup de chapitres sur les tests
* Kent Beck - Test-Driven Development By Example
  * beaucoup d'exemples de TDD
* Colin Damon - It√©rations Product(ives)
  * la moiti√© du livre est une session de TDD
* TODO @Julien Pourquoi votre strat√©gie de tests end-to-end √©choue ?
* Martin Fowler - Refactoring (2√®me √©dition fran√ßaise, 2019)
  * 1 chapitre : Cr√©ation des tests
  * 15 pages sur 410

-v-

### Manquants

* Lisa Crispin et Janet Gregory - Agile Testing
* Ward Cunningham - Growing Object-Oriented Software Guided by Tests
* Baptiste Lyet - Unit Testing
* Emily Bache - How to test legacy code
* Mitchell Hashimoto - Can we test it? Yes we can

---

# Exemple de citation trompeuse

> "I get paid for code that works, not for tests [...]"

- Kent Beck

[...]

> I get paid for code that works, not for tests, so my philosophy is to test as little as possible to reach a given level of confidence (I suspect this level of confidence is high compared to industry standards, but that could just be hubris).
> If I don't typically make a kind of mistake (like setting the wrong variables in a constructor), I don't test for it
> I do tend to make sense of test errors, so I'm extra careful when I have logic with complicated conditionals.
> When coding on a team, I modify my strategy to carefully test code that we, collectively, tend to get wrong.

Source : [Stack Overflow en 2008 : "How deep are your unit tests?"](https://stackoverflow.com/a/153565/11384184)

---

# Abstract

L'enfer des tests auto

Des tests automatiques, on sait qu'il faut en faire. Mais trop souvent c'est une v√©ritable corv√©e : c'est lent, pas fiable, compliqu√© √† lancer, compliqu√© √† maintenir, voire compliqu√© √† √©crire tout court. Pourquoi c'est si dur ? Et comment reprendre le contr√¥le ?

Il va falloir reprendre depuis le d√©but : pourquoi on teste ? et on teste quoi ? et on teste comment ?
Ensuite, il va falloir revoir un peu les bases du test : un brin de vocabulaire, et surtout de la m√©thodologie (d√©pendances, interfaces, contrat, mock, simulateur, fixture, inversion, ...).
On fera un petit d√©tour par l'architecture, parce que la testabilit√© est une propri√©t√© √† prendre en compte d√®s le design, ou bien il faudra jouer du scalpel ou du pied-de-biche par la suite pour les faire rentrer.
Enfin, on passera √† l'impl√©mentation, et avec quelques bonnes pratiques et le bon outillage (framework de test, TestContainers, CI, ...), √ßa se passera plut√¥t bien.

A travers des cas concrets tir√©s de nos exp√©riences, suivez-nous sur le chemin pour quitter l'enfer des tests.
