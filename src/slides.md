# L'enfer des tests autos

Notes:
* TODO :
  * exemples concrets tout du long
  * exemples de code/archi √† la fin
  * images
  * FIXME: the slides should be vertical (cf mkslides_config.yml)

---

# 0. Introduction

Notes:
* TODO :
  * illustration de chapitre ?

-v-

## Disclaimer on n'est pas parfaits

Notes:
* on n'est pas parfait, des fois on ne teste pas (assez), ou pas auto

-v-

## Sondage : qui trouve que c'est l'enfer

Notes:
* qui trouve que les tests c'est l'enfer ? Qui trouve que c'est le paradis ? le purgatoire ?

-v-

## Pr√©sentation

Julien Lenormand üòá

Jonathan Gaffiot üëπ

Notes:
* TODO :
  * garder cette section ici ?

-v-

## Tester ?

Notes:
* c'est quoi tester ? c'est quoi tester automatiquement ? (moment chiant avec des d√©finitions)
* action, r√©action, stimuli, SUT
* Qualit√© avec un grand Q : (d'apr√®s Rambo Python) fiabilit√©, maintenabilit√©, √©volutivit√©, s√©curit√©
    * mentionner ISO-truc pour une autre d√©finition (plus large)

---

# 1. Pourquoi c'est important les tests autos ? (il faut le rappeller !)

Notes:
* TODO :
  * illustration de chapitre ?
  * @Julien refaire une passe sur les r√©p√©titions (cf r√©union du mercredi 08 octobre)
  * scientific proofs of efficiency ?

-v-

## Confiance

Notes:
* s√©r√©nit√©
* mise en prod le vendredi apr√®s-midi
* confiance dans ce qui a chang√©, confiance dans ce qui n'a pas chang√©

-v-

## Feedback rapide

Notes:
* ownership de la qualit√© du code, ce n'est pas juste aux QAs, ou utilisateurs de trouver les bugs, "√ßa marche sur ma machine"
* la qualit√© c'est une d√©marche, un tamis, un empilement (vrai sens de Kanban), une culture (LEAN, Kanban "right the first time")
* facile √† ex√©cuter : un clic et c'est bon, √ßa part en prod

-v-

## Qualit√© (fiabilit√©) du code

Notes:
* et les autres ? maintenabilit√©/√©volutivit√©/s√©curit√© !
* s'autoriser le refactoring, conserver du code maintenable
* stabilit√© / perennit√© / scalabilit√© humaine-temporelle-technique-complexit√©-busfactor
* quelle valeur √† un logiciel qui ne peut pas √™tre test√© automatiquement ? uniquement court-terme
* pas d'autom == risque projet
* une certaine forme de sp√©cification (c'est plus simple de savoir ce que le code doit faire, quand c'est litt√©ralement commit√© dans le repo)
    * et encore mieux, elle se v√©rifie toute seule !!
* ex√©cution automatique/syst√©matique -> pas besoin de devoir s'en souvenir (CI, make, ...)
* emp√™che le "Fear driven development"

-v-

## √âthique professionnelle

Notes:
* (cf Craft), d√©ontologie
* responsabilit√© en tant que dev, que Crafteur, que prestataire; que ...
* crit√®re de validit√© de ce qui est livr√© ("si c'est pas test√©, c'est r√©put√© ne pas marcher")
* pas oblig√© de faire comme les autres
* livraison, recette
* maturit√© professionnelle

-v-

## Rentabilit√©

Notes:
* Accelerate
* TODO autres preuves d'efficacit√© ? (cf scientific proofs)

-v-

## Seul moyen de tenir la cadence

-v-

## C'est vachement bien !

Notes:
* une fois qu'on s'est dit √ßa, √ßa para√Æt vachement bien, donc y'a aucune raison de pas en faire
* meme avec l'image recto/verso, ville en feu, b√©b√© zombie
  * "Kid Thrown In The Air Meme: How Dad Sees It Vs How Mom Sees It" cf https://i.imgur.com/qL915f0.jpeg
* Stop au masochisme ! (TODO: autre section ?)
* transition vers la partie suivante

---

# 2. Pourquoi c'est difficile les tests autos ? (il faut bien l'avouer !)

Notes:
* TODO: le formuler de fa√ßon √† r√©pondre au chemin de cr√™te ?
* TODO: ajouter des exemples concrets √† chacun

-v-

## Chemin de cr√™te

Notes:
* m√©taphore du chemin de cr√™te : facile de tomber

-v-

## Pas appris

Notes:
* sauf pour les testeurs de m√©tier, les moldus s'en passeront bien ?
* pas de formation dans la plupart des cursus master, ou bien th√©orique ou tr√®s court
* assez peu pr√©sent dans la litt√©rature g√©n√©raliste, malgr√© sa pr√©valence et importance (cf biblio)
* pas un sujet "sexy" (formation continue, conf√©rences, ...)
* exemple Ensimag, mon cursus versus ce qui est propos√© actuellement
    * Mon √®cole d'ing√©, ni mon DUT ne m'ont enseign√© le test
    * Le test √®tait une option, une ann√©e, d'une fili√®re
    * les cours de Groz sur la v√©rif statique et la mod√©lisation boite noire
    * le cours de derni√®re ann√©e
        * @Julien TODO quentin pign√©

-v-

## Vocabulaire confusant

Notes:
* personne n'est d'accord sur rien : 47 pyramides diff√©rentes, le vocabulaire du test,~~les perspectives tech~~, les r√¥les, les niveaux de test
* lister et illustrer avec diff√©rents types de pyramides
    * blague illuminatis (pyramide)
    * On est des √®gyptiens, on a plein plein de pyramides diff√®rentes
* Mike cohn pyramide des tests 2009, (martin fowler ??)
* Floril√®ge des autres formes : ice cream, hourglass, diamond, upside-down pyramid, trophy (kent beck) ... --> aucune solution universelle
    * https://claude.ai/chat/3ff66008-4cc7-431e-9657-9f4987e7d86c
* Dimensions de la pyramide : vitesse d'ex√©cution, co√ªt √† √©crire/maintenir, quantit√© de code exerc√©e, fid√©lit√© utilisateur, ...
* Le test c'est un sujet transverse our chaque dev, qu'importe le langage, la stack, le m√©tier, ... Donc tout le monde parle de quelque chose avec un point de vue et un focus diff√®rent, pas toujours mentionn√©
* pr√™t-√†-penser
    * dans quels contextes-projets travaillent les diff√©rentes personnes qui ont propos√© ces pyramides ? et en quelle ann√©e ?
    * ne suffit pas pour appr√©hender le test
* jeu des 7314 diff√©rences : industrie, technos, maturit√© du produit, dur√©e de maintenance, culture d'√©quipe, comp√©tences lacunaires, vitesse, confiance, ...
    * il n'y en a pas qu'une seule, mais une par projet ! chaque projet est diff√©rent !
    * chaque projet est (quasi) unique
* anecdote sur le vocabulaire pas unifi√© : du temps de mon stage en autom de test, j'avais travaill√© entre autres sur un glossaire unifi√© entre ISTQB et CFTL
* meilleure d√©finition des axes : "finalit√©, granularit√©, modalit√© d'assertion" (50 shades ...)
* essayons de poser une d√©finition, dans notre contexte, des mots que nous employons
    * diff√©rences entre ISTQB et CFTL, cf mon stage Sogeti
* tous les diff√©rents types de test : carac, fonc, integ, unit, acceptance, user-testing, accessibility, composant-unitaire versus composant-UI, e2e-stack ou e2e-sc√©nario...
    * TODO more
    * charge : soak, breakpoint, ... (cf doc de k6 avec de jolis graphiques)
        * K6 typologie : breakpoint, soak, stress, load, ...
    * cf ISO 15010
    * peu de personnes, m√™me dans des livres (exemple Clean Code de Robert C Martin "Uncle Bob"), ne font l'effort de d√©finir
    * Pyramyde invers√© de la valeur : le haut niveau est le plus pertinent, mais cher et fragile ?
        * Facilitation des tests web d'ui (selenium, cypress, playwright)
* QA vs QE vs testeur vs "dev" vs IVVQ vs ...
* Test error vs test failure : le test n'a pas abouti pour une raison technique (probl√®me de test), le test a abouti mais n'a pas produit le r√©sultat attendu (probl√®me fonctionnel on esp√®re !)

-v-

## Trop de tests

Notes:
* explosion combinatoire
* cible mouvante et floue

-v-

## Pratique r√©ticente

Notes:
* des tonnes d'outils diff√©rents, les diff√©rents types de tests √©voqu√©s, les diff√©rents m√©tiers, l'insertion dans le process de production, ...
* s'organiser, planifier et r√©aliser sont des t√¢ches complexes

-v-

## Punition

Notes:
* l'absence de testeur/expertise/culture dans les projets (des gens form√©s, motiv√©s, avec le mindset ad√©quat)
* > On peut conduire un cheval √† l'abreuvoir, mais pas le forcer √† boire
* comme beaucoup de sujets, c'est pas un casse-pied de service qu'il faut, mais un changement de culture (beaucoup plus compliqu√©, cf Agile bullshit)

-v-

## Inutile

Notes:
* convaincre (le management et/ou les devs) que c'est utile, avant de se manger une mise-en-prod foir√©e
* d√©pense versus √©conomie

-v-

## Test impossible

Notes:
* imitations techniques, mat√©rielles, de co√ªt, ... variabilit√© selon les environnements
* exemple board farm Schneider
* exemple Windows 10 LTSC 2019 √† Thales

-v-

## Code intestable

Notes:
* Ennemis : side-effects ("spooky action at a distance", "que fait cette m√©thode ?"), (global/static) state, IO, singletons, time, locale, network, files, env, GPU, unclear pre/post-conditions, non-determinism, (G)UI vs API, concurrency et threading, random (non-deterministic), complex outputs and high dimensionality
* diff√©rence entre "c'est compliqu√© de r√©aliser le test" (limitations tech) versus "c'est compliqu√© d'√©crire le test" (iceberg, gorille)
* exemple : code des bornes qui √©choue le 29 F√©vrier
* exemple : code du Edge qui est correct sur la timezone 6 mois par an

-v-

## Fragile

Notes:
* couplage versus maintenabilit√© en carton, tests cass√©s pas r√©par√©s ("vitre cass√©e"), maintenance des tests v√©cue comme un fardeau
  * le summum : test de mock !
* Tester le mauvais 80% : m√©taphore du streetlight problem ("plus simple de chercher dans la lumi√®re")
* test flaky
  * l'√©quivalent de "pt√®t bin qu'oui, pt√®t bin qu'non"
  * suffit de les relancer plusieurs fois mdr, ~z√©ro confiance

-v-

## Illisible

Notes:
* exemple d'Eric (Schneider)

-v-

## Lent

Notes:
* lenteur, car tests lents et/ou trop de tests
* exemple de Xavier Nopre (cf post LinkedIn), je lui ai dit qu'il y avait un probl√®me, c'est pas cens√© √™tre aussi lent
* exemple de Schneider : board farms
* exemple de Schneider : code dont le run dure des centaines jours !! (√† travers les timezones :p)

-v-

## Bug ou feature ou code mort ?

Notes:
* descriptivism vs prescriptivism (cf Romeu)
* test de caract√©risation OK, mais est-ce que c'est ce que √ßa devrait vraiment faire ? ü§∑
  * bug ou feature ?
* source de v√©rit√© = code ou spec Word ?

-v-

## En Bref

Notes:
* difficile de savoir quoi faire, Todo : retrouver comment faire, de le faire, √† ex√©cuter, √† analyser, √† maintenir, √† faire confiance, pas assez, pas assez bien, pas assez rapide, ...
* Facile √† dire de faire "le bon test", mais concr√®tement ?
  * y'a le bon testeur et le mauvais testeur ...
* transition

---

# 3. Comment faire pour bien tester auto ? (il faut s'aider !)

Notes:
* TODO:
  * orient√© solution cf partie pr√©c√©dente orient√© probl√®me ?
  * le formuler de fa√ßon √† r√©pondre au chemin de cr√™te
  * mentionner "se rendre dispensable" ? (vis-√†-vis du scaling humain)

-v-

## Chemin de cr√™te

Notes:
* comment le naviguer ? comment √™tre/devenir/rester rigoureux ?

-v-

## Culture de la qualit√©

Notes:
* culture qualit√©, formation (cours, conf√©rences, livres, exercices, katas, ...)
* cf nos recos √† la fin, exp√©rience (empirisme)
* compr√©hension du business et des stakeholders,
* tournure d'esprit (cf joke "un testeur rentre dans un bar, il commande -1 bi√®re, NaN bi√®re, demande o√π sont les toilettes ..."), "vicieux" pour "casser le code" et non pas seulement montrer qu'il fonctionne 
* exemple : SQLite testing, test code ratio, test harnesses, ... (+√©volution dans le temps)
* le code il faut le malmener
* la qualit√© c'est un ensemble de tamis successifs : empilement de couches pour attraper les bugs, du besoin, design, archi, implem, test, validation, d√©ploiement
  * processus/d√©marche au niveau deD√©finition de test unitaire contre-intuitive : ne pas penser microscopique/indivisible, mais coh√©rence/s√©paration-fronti√®re l'√©quipe/projet/entreprise/...
* exemple : NDP Systems
* "Le test n'apporte pas de valeur (argent) par rapport aux fonctionnalit√©s"
* Humilit√© de devoir tester

-v-

## Strat√©gie de test

Notes:
* quoi pourquoi pour quoi comment qui quand ...
* sp√©cifications, Exigences et Requirements, business (value stream) et risques business, quadrants, matrice confiance versus risque, moyens (et toute la suite)
* construisez votre "pyramide" (demander √† une IA diK6 typologie : breakpoint, soak, stress, load, ...ff√©rente pyramides, de plein de formes diff√©rentes √† la Dali), en se basant sur les moyens de test
* √† adapter/repenser r√©guli√®rement, comme tout le reste
* pourquoi, pour quoi, quoi, o√π, qui, quand et comment, ...
* trust boundaries (d√©pendences externes, parties peu fiables, risque m√©tier, responsabilit√©, vitesse d'√©volution, ...)
* Repenser la strat fr√©quemment, tout comme on le fait pour l'architecture de la solution
* consid√©rer les niveaux de test : Fonctionnalit√©s techniques (endpoint) versus user
* Quadrant des tests !! Axes : business vs tech, pour le produit vs √®quipe

-v-

## Moyens de test

Notes:
* humains, techniques, teTodo : retrouver mporels, ...
* outils de test, formations, avoir le temps, d√©ployabilit√©, disponibilit√© du hardware, dispo des data, ...
* avoir des specs ! (claires)
* pas de bras, pas de chocolat

-v-

## Renoncer

Notes:
* renoncer √† tout automatiser (quadrants, moyens insuffisants, ...), ROI
* tradeof : cout, risque, complexit√©, ...
* crit√®re qui favorisent l'automatisation : r√©p√©tition, confiance dans l'autom, p√©nibilit√©, longueur, criticit√©, ...
* il vaut mieux un mix d'autom et de manuel, la force de chacun
* Le co√ªt des tests est parfois sup√©rieur aux ben√©fices
* exemple : lecteur de fichier √† EDF
* Tester le code techniquement complexe, sensible pour le m√©tier, et utile
* loi de pareto 80/20 : toujours fausse, toujours vraie
* hybrid possible aussi (soit manuel assist√© par autom, soit autom avec verif manuelle) : continuum Automatis√©-automatisable-manuel
* Sans jugement : un pas apr√®s l'autre, on h√©rite de codebases, on essaye de faire mieux
  * incr√©mental
* tester ne prouve pas l'absence de bugs, mais en √©limine certains  
* process avec des rendements d√©croissants, trouver le bon curseur, le bon √©quilibre
* garder des tests qu'on appr√©cie : rapides (ou moins rapides en CI mais + couvrants), fiables, maintenables, estimer le ROI
* OK de supprimer un test inutile

-v-

## Processus

Notes:
* (reprendre des tamis) : tres amigos, example mapping, BDD, prise en compte de la testabilit√© d√®s la (pr√©-)conception, compter le co√ªt du test dans l'estimation de la story, les tests font partie de la dette technique du projet, analyse d'impact lors de nouveaux devs, d√©coupage en √©quipe Dev versus QA ??
  * identifier les manquements dans son √©quipe, sur son projet, et trouver comment communiquer dessus avec les autres, avoir des id√©es √† proposer

-v-

## Sc√©narios

Notes:
* c√©narios de test (nominaux, critiques, ...) d√©cid√©s, "use cases" (orient√©s "utilisateur" de l'interface)
* TODO retravailler cette section
* typologie de test : "unitaire au niveau technique (m√©thode/classe)", ou "unitaire d'interface mais profond"
* avoir une spec
  * Exigences et Requirements (cf Schneider, Thales, ...)
* value streams, risques, manque de confiance, ...
* smoke tests (cf origine du mot "smoke test" en logiciel)

-v-

## Architecture testable

Notes:
* sinon architecture intestable ou semi-testable
* seams (cf Michale feathers, Working effectively with legacy code) versus scalpel et pied-de-biche
* d√©pendances, interfaces, contrats, ... "trust boundaries"
* you can't write good tests for badly written code
* version de dev, suffisament isoprod mais avec des backdoors
* attention au couplage : ni trop peu, ni pas assez (monolithe spaghetti versus micro-services passe-plats)
  * plus simple de tester des fonctions (niveau code) que des programmes
* functionnal core, imperative shell (ou h√©xagonal, ou onion)
* pousser les IO √† l'ext√©rieur (techniqTodo : retrouver ue du sandwich)
* design goal sinon accidentel
* crit√®re d'acceptabilit√©
* state is the enemy, prog fonctionnelle
* narrow interfaces for deep modules
* "fracture planes" de Team Topo, selon des "lignes de faille" (user persona, tech, change cadence, regulatory compliance, team location, risk, performance isolation, ...)
  * cf https://teamtopologies.com/key-concepts-content/finding-good-stream-boundaries-with-independent-service-heuristics
  * cf https://yoan-thirion.gitbook.io/knowledge-base/xtrem-reading/resources/book-notes/team-topologies#software-boundaries-or-fracture-planes
* sans architecture testable, la strat s'effondre !

-v-

## Surface d'interface

Notes:
* TODO: sous-partie de l'architecture testable ?
* ma√Ætriser la surface de test du code
* Tester aux fronti√®res d'une interface, que ce soit une m√©thode priv√©e, publique, classe, module, programme, sous-syst√®me, syst√®me, sur-systeme
* facile pour des modules narrow-interface mais deep, impossible pour des hubs
* les "unit" tests n'ont pas vocation √† tester le moinds de lignes possible, mais √† tester des APIs
* Ne pas tester tout le code ? Cf couverture, et faire des tests crois√©s
* Quantit√© de test versus qualit√©
* contravariance, tester l'interface plut√¥t que l'impl√©mentation, cf Uncle Bob https://blog.cleancoder.com/uncle-bob/2017/10/03/TestContravariance.html

-v-

## Feedback

Notes:
* fast feedback + CI/CD + DevOps (monitoring, observability), frequent deployment, Monitoring, debuggability

-v-

## Fluide

Notes:
* ajouter un test doit √™tre simple, s'il y a de la friction alors √ßa d√©courage de tester, il faut √©liminer la friction
* sentir la douleur : "If it hurts, do it more often" (core XP principle)
* ne pas √™tre capable de r√©aliser les tests rapidement diminue l'it√©rativit√©, la qualit√©, l'agr√©abilit√©, ... la probabilit√© qu'ils soient √©crit tout court
  * comme un √©vier plein de vaisselle (cercle vicieux)
* Blague du docteur : "j'ai mal quand je suis debout" "alors arr√™tez de vous lever"

-v-

## Investissement

Notes:
* investissement dans un second logiciel pour mieux produire le premier
* outils de test
* investir dans le futur
* projet logiciel = le code qui part en prod, mais pas seulement, aussi : la doc, la CI, les specs, et donc aussi les tests, ...
* "Le test n'apporte pas de valeur (argent) par rapport aux fonctionnalit√©s" (et les fonctionnalit√©s non plus d'ailleurs, √ßa d√©pend si elles sont connues, utilis√©es, ...)
* Second-syst√®me de stabilisation du premier, par opposition √† la flexibilit√©
* Une s√©curit√©, ou un frein ? les deux ?
* exemple de SQLite (x 590)
* Vraiment √† retenir : ne pas penser le test comme un apr√®s, mais comme un m√™me temps, voire enabler

-v-

## Ecriture

Notes:
* m√©thodologie d'√©criture : setup/teardown, Given/When/Then, Assert/Arrange/Act, tester une seule chose plut√¥t qu'un sc√©nario complet, erreur versus √©chec
* FIRST : https://stackoverflow.com/questions/18024785/tdd-first-principle Fast Indep Repeat Self-Check Timely (pas √©crit dans 1000 ans mais avec le code √† tester)
  * double i : isolation ?

-v-

## Techniques

Notes:
* ce qu'on consid√®re le minimum √† ma√Ætriser pour tester
* test harness
* TestContainers
* framework
* mocking et fakes versus simulateurs/√©mulateurs, oracles
  * qu'est-ce je gagne et je perds si je mocke ? gain = vitesse d'exec + facile √† mettre en oeuvre (autospec), perte = maintenabilit√© et r√©alisme
  * TODO: ne pas mentionner les 2 √©coles, mettre en aller en + loin
* DB in-memory

-v-

## techniques avanc√©es

Notes:
* outils et techniques <<avanc√©s>>, pour aller + loin (et qui m√©rite chacun son 45 minutes ou +) pour d√©velopper culture et savoir-faire
* TODO trier/ordonner ces techniques
  * quelques-unes principales, d'autres justes √©nonc√©es ?
* advanced features of pytest (or your framework), know your tools
  * fixture
  * mock
  * plugins
* TU : D√©finition de test unitaire contre-intuitive : ne pas penser microscopique/indivisible, mais coh√©rence/s√©paration-fronti√®re
* TDD (cf on peut pas oublier de les faire √† la fin si on les fait au d√©but), diff√©rents sens du mot TDD, ...
  * cf slides ABC + Discovery Day
  * Mon tddd : testable design
  * "Tdd malgr√® son nom n'est pas une technique de test mais de design"
* mock et doublures : mock fake stub spy
  * Cf martinfowler (en ref √† la fin)
* chaos monkey + chaos engineering, cf Netflix + [Chaos Monkey Army](https://github.com/Netflix/SimianArmy/wiki/The-Chaos-Monkey-Army)
* ATDD versus BDD (parcours versus comportement segment√©, cf la Taverne)
* snapshot/golden-master/approval
  * normatif versus descriptif
* fake time (freezegun en Python, libfaketime + LD_PRELOAD), Reactive instead of passive polling ou sleeping, 
* Ab testing
  * canary release, alpha testing, beta testing, blue-green, ...
  * Field testing (schneider)Dimensions de la pyramide : vitesse d'ex√©cution, co√ªt √† √©crire/maintenir, quantit√© de code exerc√©e, fid√©lit√© utilisateur, 
  * user acceptance ?
* sans io
* architecture h√©xagonale
* programmation fonctionnelle
* IA
* mesure de la couverture de test
  * Code coverage : line/branch/cond
  * 80 ? 90 ? 99 ?
  * Ne suffit pas !!!
  * Cf "1 / 0" avec 100% de coverage.
  * Ou "foo.update()" si foo est null
  * Il y a des branches invisibles (exceptions, donn√©es mal model√©es)
* test guid√© par la couverture (sans mention de pourcentage)
  * pour orienter les tests
* surveiller la performance des tests autos
  * ne correspond pas aux tests de performance
* security testing
* load testing (rendu accessible par de l'outillage, mais reste rare et hyper-sp√©cifique en terme de sc√©nario)
* table testing
* full simulation ("Matrix") : cHumilit√© de devoir testerf conf Devoxx (simulation-driven development)
  * replay du talk CleverCloud au Devoxx sur la simulation du testbench
  * Conf Devoxx 2025 sur le d√©terminisme CleverCloud
* contract testing
  * Test d'interface d'une third-party (rupture d'API, ...)
* recording/replaying (VCR)
* monkey testing (Doublures de test : des inputs au hasard, le test n'est pas structur√©)
* profile your tests ! (√©viter les "slips/sleeps sales") cf snakeviz marche aussi pour les tests (cf article de Xavier et son setup de DB), tests en parall√®le (cf article du blog de PyPi), √™tre r√©actif plut√¥t que passif (cf MQTT tester de Schneider)
* property-based testing + fuzzing
* trunk-based development + feature flags
* monitoring en prod
* Snapshot-testing (approval, golden master)
* Technique de refactoring du sandwich (snowcamp) : push IO to the edge (functional core, imperative shell)
* Mockist vs Behaviorist (detroit vs london)
* Test d'√®chafaudage (scaffolding)
* (London versus Chicago, Classicist versus Mockist)
* tests d'architecture (Java = ArchUnit, Python = PyTestArch)
* Security testing : automated tools
* Black box / white /glass
* Baseline perf comparison testing
* time : freezegun en Python, libfaketime avec LD_PRELOAD sinon
  * exemple : tester du code qui doit s'ex√©cuter pendant des mois (harness de test d'endurance)
* r√¥le de l'IA dans les tests ? (cf Tao blue/red team)
*  property(/fuzzing) (cf article sur la diff√©rence)
* advanced features of pytest (or your framework), know your tools
* sans_io
* systrace/ptrace
* HTTPS Man-in-the-Middle (MITM proxy par exemple)
* trucage DNS via `/etc/hosts` ou `/etc/resolv.conf`
* `ssl_verify=False`
* test des logs/metrics (cf mon post LinkedIn)
* test hybride : test auto avec v√©rif humD√©finition de test unitaire contre-intuitive : ne pas penser microscopique/indivisible, mais coh√©rence/s√©paration-fronti√®reaine, ou test manuel avec assistance autom
* anonymiser des donn√©es (de prod)
* g√©n√©rer des donn√©esmartin fowler

---

# 4. Cas pratique

Notes:
* TODO : 3 exemples de test
  * fonction pure (mais avec de la complexit√© interne), quelques cas d'erreur pr√©vus -> tests fonc, table, edge cases, fuzz, property-based
  * API WEB : mock, contrat, VCR, fake d'API
  * gros Postgres legacy, nouvelle feature

---

# 5. Conclusion

Notes:
* expertise indispensable, il faut s'y mettre, dans un environnement semi-hostile (vocab, √©quipe, rythme, outillage, ...) -> CI, run local. C'est une partie de l'ing√©nierie

---

# 6. Nos recommandations

Notes:
* TODO
* replay vid√©o (Youtube) de LyonCraft 2025 : [Jeremy Sorent "j'√©cris de tests sans pleurer maintenant"](https://www.youtube.com/watch?v=2S9TxoTE8BA)
    * @Julien TODO: revoir
* working effectively with legacy code
* software craft, dunod
* taverne
* https://www.joelonsoftware.com/2001/07/31/hard-assed-bug-fixin/ : est-ce que tous les bugs devraient √™tre corrig√©s ? √ßa d√©pend.
* https://www.mathieueveillard.com/blog/50-shades-of-tests : des d√©finitions plut√¥t claires pour diff√©rents types de test, leur positionnement sur 3 dimensions, au-del√† de la pyramide de tests
* https://martinfowler.com/bliki/TestDouble.html : d√©finitions claires de tous les "*test doubles*" (dummy, stub, fake, spy, mock)
* https://latavernedutesteur.fr/2025/09/15/que-doit-on-attendre-dun-testeur/ : les diff√®rentes dimensions du m√©tier de testeur
* le DevOps (TODO trouver une bonne r√©f√©rence ? conf Full Cycle d'Alpes Craft)
* [la strat de test de Colin Damon](https://www.linkedin.com/posts/colin-damon_mettre-en-place-une-strat%C3%A9gie-de-tests-qui-activity-7343525861444247552-6BJY)
* [How SQLite Is Tested](https://www.sqlite.org/testing.html)
* http://rednafi.com/go/test-state-not-interactions/
* https://blog.codinghorror.com/falling-into-the-pit-of-success/
* [Tests pragmatiques : comment presque arreÃÇter les tests automatiseÃÅs ? - La Duck Conf 2025](https://m.youtube.com/watch?v=ohV6GvCIeLY)
* Conf snowcamp 2025, "tester c'est tricher" de JAutomatis√©-automatisable-manuelules Poissonnet et Antoine Caron
* [Comment une architecture influence votre strat√©gie de test ? Par Christophe Br√©heret-Girardin - La Duck Conf 2024](https://m.youtube.com/watch?v=IeOa6XWxkxg)

---

# Cr√©dits photos

Notes:
* TODOD

---

# Remerciements

Notes:
* Damien Roulier, Eric Papazian, Mathieu Mattringe, Rachel Da Silva

---

# Questions

Notes:
* TODO image
